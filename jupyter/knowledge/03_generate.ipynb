{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1257258b-c279-43a3-b73f-1efd12c69382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from transformers.utils import is_flash_attn_2_available \n",
    "from nn_rag import Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c939bcdb-2dd8-4e46-98c1-b14dd45bb2e7",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e6a503a-42b4-449e-916d-0457b20a634d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nn_rag.components.retrieval.Retrieval at 0x7f8ca2bcb3a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag = Retrieval.from_memory()\n",
    "rag.set_source_uri('chroma:///hadron/data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd8c44a-b171-4480-8780-7dd3ca9098de",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c84f33be-92be-48a3-93e9-5e5ddb53e96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcddeb592cea454e88590439295dcef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "model_id = 'google/gemma-2b-it'\n",
    "\n",
    "if (is_flash_attn_2_available()) and (torch.cuda.get_device_capability(0)[0] >= 8):\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "else:\n",
    "    attn_implementation = \"sdpa\"\n",
    "    \n",
    "# 4 bit quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16, # gain back some speed \n",
    "    bnb_4bit_quant_type=\"nf4\", # weights initialized with normal distribution\n",
    "    bnb_4bit_use_double_quant=True, # better memory footprint\n",
    "    llm_int8_enable_fp32_cpu_offload=True, # offload weights cross GPU and CPU\n",
    ")\n",
    "\n",
    "# instantiate the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=None,\n",
    "    device_map='cpu',\n",
    "    attn_implementation=attn_implementation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "492f965e-0891-41f1-b542-ba9e2fe5a3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model Size: 2,506,172,416 parameters'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_num_params(model: torch.nn.Module):\n",
    "    return sum([param.numel() for param in model.parameters()])\n",
    "\n",
    "f\"Model Size: {get_model_num_params(model):,.0f} parameters\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409a3a22-21fb-442d-83dc-b5ae2eb585af",
   "metadata": {},
   "source": [
    "### Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4fa98ac-f8d0-462e-9b4e-69f181791e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_formatter(query: str, context_items: list[dict]) -> str:\n",
    "    \"\"\"\n",
    "    Augments query with text-based context from context_items.\n",
    "    \"\"\"\n",
    "    # Join context items into one dotted paragraph\n",
    "    context = \"- \" + \"\\n- \".join([item for item in context_items[\"text\"].to_pylist()])\n",
    "\n",
    "    # Create a base prompt with examples to help the model\n",
    "    base_prompt = \"\"\"Based on the following context items, please answer the query.\n",
    "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
    "Don't return the thinking, only return the answer.\n",
    "Make sure your answers are as explanatory as possible.\n",
    "Use the following examples as reference for the ideal answer style.\n",
    "\\nExample 1:\n",
    "Query: What are the core principles of responsible AI mentioned in the guide?\n",
    "Answer: The guide outlines core principles of responsible AI, which include fairness and inclusion, robustness and safety, privacy and security, and transparency and control. Additionally, it emphasizes the importance of governance and accountability mechanisms to ensure these principles are upheld throughout the development and deployment of AI systems.\n",
    "\\nExample 2:\n",
    "Query: How does Meta's open approach contribute to AI innovation?\n",
    "Answer: Meta's open approach to AI innovation involves open-sourcing code and datasets, contributing to the AI community's infrastructure, and making large language models available for research. This approach fosters a vibrant AI-innovation ecosystem, driving breakthroughs in various sectors and enabling exploratory research and large-scale production deployment. It also draws upon the collective wisdom and diversity of the AI community to improve and democratize AI technology.\n",
    "\\nExample 3:\n",
    "Query: What are the stages of responsible LLM product development according to the guide?\n",
    "Answer: The guide identifies four stages of responsible LLM product development: determining the use case, fine-tuning for the product, addressing input- and output-level risks, and building transparency and reporting mechanisms in user interactions. Each stage involves specific considerations and mitigation strategies to ensure the safe and effective deployment of LLM-powered products.\n",
    "\\nNow use the following context items to answer the user query:\n",
    "{context}\n",
    "\\nRelevant passages: <extract relevant passages from the context here>\n",
    "User query: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Update base prompt with context items and query   \n",
    "    base_prompt = base_prompt.format(context=context, query=query)\n",
    "\n",
    "    # Create prompt template for instruction-tuned model\n",
    "    dialogue_template = [\n",
    "        {\"role\": \"user\", \"content\": base_prompt}\n",
    "    ]\n",
    "\n",
    "    # Apply the chat template\n",
    "    prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                          tokenize=False,\n",
    "                                          add_generation_prompt=True)\n",
    "\n",
    "    return prompt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce0300e-ae5b-44d2-bb83-897875e37402",
   "metadata": {},
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65b57981-6397-4b86-9176-e19941b75a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query, \n",
    "        temperature=0.7,\n",
    "        max_new_tokens=512,\n",
    "        format_answer_text=True, \n",
    "        return_answer_only=True):\n",
    "    \n",
    "    # Get the query answers from the embedding\n",
    "    context_items = rag.tools.query_reranker(query=query)\n",
    "    \n",
    "    # Format the prompt with context items\n",
    "    prompt = prompt_formatter(query=query, context_items=context_items)\n",
    "    \n",
    "    # Tokenize the prompt\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to('cpu')\n",
    "\n",
    "    # Set tokenize terminators\n",
    "    terminators = [\n",
    "        tokenizer.eos_token_id,\n",
    "        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    # Generate an output of tokens\n",
    "    outputs = model.generate(**input_ids,\n",
    "                             eos_token_id=terminators,\n",
    "                             temperature=temperature,\n",
    "                             do_sample=True,\n",
    "                             max_new_tokens=max_new_tokens,\n",
    "                             top_p=0.9,\n",
    "                            )\n",
    "    \n",
    "    # Turn the output tokens into text\n",
    "    output_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "    if format_answer_text:\n",
    "        # Replace special tokens and unnecessary help message\n",
    "        output_text = output_text.replace(prompt, \"\").replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").replace(\"Sure, here is the answer to the user query:\\n\\n\", \"\")\n",
    "\n",
    "    # Only return the answer without the context items\n",
    "    if return_answer_only:\n",
    "        return output_text\n",
    "    \n",
    "    return output_text, context_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab64716-d95a-494d-b2bb-aa204fe3f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = outputs[0][input_ids.shape[-1]:]\n",
    "# print(tokenizer.decode(response, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9418952-94b3-464e-822a-2bcbbc184841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    print(wrapped_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0bb08f2-6bf5-4bfe-910b-d5fe1b9b9047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What considerations should be taken into account when defining layers of safety for LLMs?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/neural/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "\n",
      "The passage does not provide any specific considerations for defining layers of\n",
      "safety for LLMs, so I cannot answer this question from the provided context.\n",
      "Context items:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "id: string\n",
       "distance: float\n",
       "score: float\n",
       "text: string\n",
       "----\n",
       "id: [[\"general_34\",\"general_14\",\"general_37\",\"general_29\",\"general_28\"]]\n",
       "distance: [[1.3796693,1.4776846,1.4794096,1.4501711,1.4373482]]\n",
       "score: [[0.618675,0.5823165,0.55936307,0.52328396,0.51588774]]\n",
       "text: [[\"There are many complementary types of evaluations that are useful for measuring risks in models, including automatic benchmarks, manual annotations by human raters, and evaluations using an LLM itself as a rater. The Holistic Evaluation of Language Models discusses some of the commonly used automatic benchmarks. Evaluation strategies and processes to improve performance can include: • Automatic evaluation leverages automatic benchmarks and classifiers to judge the output with respect to a specific category of risk. Manual evaluation leverages human annotators or subject matter experts to judge the model’s output.\",\"It is critical that developers examine each layer of the product to determine which potential risks may arise based on the product objectives and design, and implement mitigation strategies accordingly. The following section presents responsible AI considerations for the different stages of LLM product development. At each of these levels, we highlight best practices for mitigating potential risks. 5 JULY 2023 Llama 2 is a new version of the Llama 1 model, which was made available previously for research. The new pretrained and fine-tuned versions of the model have been updated for commercial release.\",\"13 JULY 2023 Address input- and output-level risks Without proper safeguards at the input and output levels, it is hard to ensure that the model will respond properly to adversarial inputs and will be protected from efforts to circumvent content policies and safeguard measures (“jailbreaking”). Mitigations at the output level can also act as a safeguard against generating high-risk or policy-violating content. Enforcement of content policies can be managed through automated systems and manual analysis of samples and reports. Automated systems may include machine learning and rule-based classifiers for filtering prompt inputs or system outputs. Usage or consequence policies may be defined for when users repeatedly violate those policies.\",\"Representativeness of data is dependent on the use case and should be assessed accordingly. When fine-tuning for a specific use case it can be beneficial to examine training data for biases, such as gender, racial, linguistic, cultural or other biases. Understanding these patterns is important but it may not always be optimal to filter out all problematic content in training data due to the unintended consequences this filtering may have on subsequent performance and safety mitigations, such as prompt engineering.\",\"The THE RESPONSIBLE FINE-TUNING FLOW STEP 2: PREPARE DATA Developing downstream applications of LLMs begins with taking steps to consider the potential limitations, privacy implications, and representativeness of data for a specific use case. Begin by preparing and preprocessing a clean dataset that is representative of the target domain. This involves tokenizing the text, handling special characters, removing unnecessary information, and splitting the dataset into training, validation, and testing sets. This step may also involve ensuring that data are representative of the end users in the deployment context, for instance, by ensuring there are enough examples from relevant languages if you plan to deploy your product in a non-English speaking market.\"]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What considerations should be taken into account when defining layers of safety for LLMs?\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Answer query with context and return context \n",
    "answer, context_items = ask(query=query, \n",
    "                            temperature=0.7,\n",
    "                            max_new_tokens=512,\n",
    "                            return_answer_only=False)\n",
    "\n",
    "print(f\"Answer:\\n\")\n",
    "print_wrapped(answer)\n",
    "print(f\"Context items:\")\n",
    "context_items['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4900b5fb-098f-42a6-b308-1997dd4030af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6516f0f9-6358-4803-acc5-47333a1597cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
