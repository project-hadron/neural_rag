{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "962e2eab-fef2-4393-8e03-836e7921a99d",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# saves you having to use print as all exposed variables are printed in the cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116bbfb0-cf0d-4946-a9ab-0430479d0e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warning message\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68bdaf3a-78fb-438b-9590-d4feb46ad151",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.compute as pc\n",
    "from nn_rag import Knowledge, Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d62f37-c1fe-4d91-aadc-231253ccf97f",
   "metadata": {},
   "source": [
    "### Chroma Vector Params\n",
    "\n",
    "        URI example in-memory\n",
    "            uri = \"chromadb:///<collection>?reference=<name>\"\n",
    "\n",
    "        params:\n",
    "            collection: The name of the collection\n",
    "            reference: a prefix name to reference the document vector\n",
    "\n",
    "        Environment:\n",
    "            CHROMA_EMBEDDING_QUANTIZE\n",
    "            CHROMA_QUERY_SEARCH_LIMIT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb5c8ff-3497-4213-a0fc-db712cb4a8a8",
   "metadata": {},
   "source": [
    "### Instantiate capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b85ae8c1-598a-4764-97b0-7b882e3fadc8",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "kn = Knowledge.from_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361cb284-9dbd-461b-9fbe-6abf87fed6c1",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "tbl = kn.set_source_uri(\"./hadron/source/llama-Responsible-Use-Guide.pdf\").load_source_canonical()\n",
    "kn.set_persist_uri('chroma:///')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7a6dec-cfc8-4d94-9b75-9bb937348452",
   "metadata": {},
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30a772c2-695d-4ad5-9c88-35b3b130d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = kn.tools.replace_on_pattern(tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d00b208-3e72-435c-bdf1-deaa89c8de35",
   "metadata": {},
   "source": [
    "### Sentence Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be78fdc2-df14-4fad-bcf2-60490b6e9629",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba33a6d6df914055a3dad962a889b23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "building sentences:   0%|          | 0/7586 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ac4b9202314e5fa5ee96507c6d5807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build sentences:   0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = kn.tools.text_to_sentences(doc)\n",
    "chunks = kn.tools.filter_on_join(sentences, chunk_size='500')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caee61a-6506-4025-99d5-d2969a320a10",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1caf4977-4398-45f5-9a48-af84a21cf7a7",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "kn.save_persist_canonical(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e792c-5d0a-4d9c-bad0-59e409c18097",
   "metadata": {},
   "source": [
    "----------------\n",
    "## Chroma Vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302065d3-638c-4500-893c-b104c9a2b2d3",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fce53daf-dc7c-4632-acd9-44565f1ca542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    return wrapped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5299de0-8f42-4084-a359-fa3d377206d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "questions = [\n",
    "    \"1. What are the core principles of responsible AI mentioned in the guide?\",\n",
    "    \"2. How does Meta's open approach contribute to AI innovation?\",\n",
    "    \"3. What are the stages of responsible LLM product development according to the guide?\",\n",
    "    \"4. What are some examples of product-specific fine-tuning for LLMs?\",\n",
    "    \"5. What considerations should be taken into account when defining content policies for LLMs?\",\n",
    "    \"6. What are the benefits of democratizing access to large language models, as stated in the guide?\"\n",
    "]\n",
    "\n",
    "query = random.choice(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eede9513-fb35-4708-b74d-10ce21e9113a",
   "metadata": {},
   "source": [
    "### Model Answers\n",
    "1. **Core principles of responsible AI:**\n",
    "   The guide outlines core principles of responsible AI, which include fairness and inclusion, robustness and safety, privacy and security, and transparency and control. Additionally, it emphasizes the importance of governance and accountability mechanisms to ensure these principles are upheld throughout the development and deployment of AI systems.\n",
    "\n",
    "2. **Meta's open approach and AI innovation:**\n",
    "   Meta's open approach to AI innovation involves open-sourcing code and datasets, contributing to the AI community's infrastructure, and making large language models available for research. This approach fosters a vibrant AI-innovation ecosystem, driving breakthroughs in various sectors and enabling exploratory research and large-scale production deployment. It also draws upon the collective wisdom and diversity of the AI community to improve and democratize AI technology.\n",
    "\n",
    "3. **Stages of responsible LLM product development:**\n",
    "   The guide identifies four stages of responsible LLM product development: determining the use case, fine-tuning for the product, addressing input- and output-level risks, and building transparency and reporting mechanisms in user interactions. Each stage involves specific considerations and mitigation strategies to ensure the safe and effective deployment of LLM-powered products.\n",
    "\n",
    "4. **Examples of product-specific fine-tuning:**\n",
    "   Product-specific fine-tuning examples provided in the guide include text summarization, question answering, and sentiment analysis. For instance, a pretrained language model can be fine-tuned on a dataset of long-form documents and summaries for text summarization, on a Q&A dataset for answering questions, and on labeled text reviews for sentiment analysis. These examples demonstrate how fine-tuning can tailor a model's capabilities to specific use cases, enhancing performance and applicability.\n",
    "\n",
    "5. **Considerations for defining content policies:**\n",
    "   When defining content policies for LLMs, developers should consider the intended use and audience of their product, legal and safety limitations, and the needs of specific user communities. Content policies should outline allowable content and safety limitations, which will guide data annotation and safety fine-tuning. It is also important to address potential biases in human feedback and data annotation processes to ensure fairness and objectivity.\n",
    "\n",
    "6. **Benefits of democratizing access to large language models:**\n",
    "   Democratizing access to large language models, as discussed in the guide, reduces barriers to entry for small businesses and fosters innovation across various sectors. By making these models widely available, small organizations can leverage advanced AI technology without incurring prohibitive costs, leading to economic growth and a more level playing field. This approach also promotes collaboration and collective improvement of AI models, ensuring that advancements benefit a broader range of users and applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fb2448a-c874-42bb-824a-48eb32fa287f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nn_rag.components.retrieval.Retrieval at 0x7fdd28adceb0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag = Retrieval.from_memory()\n",
    "rag.set_source_uri('chroma:///')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d1aaaab-ab57-47a2-884a-b382347bb41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 4. What are some examples of product-specific fine-tuning for LLMs?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d5d88 th {\n",
       "  font-size: 120%;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_d5d88 .row_heading {\n",
       "  display: none;;\n",
       "}\n",
       "#T_d5d88  .blank {\n",
       "  display: none;;\n",
       "}\n",
       "#T_d5d88_row0_col0, #T_d5d88_row0_col1, #T_d5d88_row0_col2, #T_d5d88_row1_col0, #T_d5d88_row1_col1, #T_d5d88_row1_col2, #T_d5d88_row2_col0, #T_d5d88_row2_col1, #T_d5d88_row2_col2, #T_d5d88_row3_col0, #T_d5d88_row3_col1, #T_d5d88_row3_col2, #T_d5d88_row4_col0, #T_d5d88_row4_col1, #T_d5d88_row4_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d5d88\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d5d88_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
       "      <th id=\"T_d5d88_level0_col1\" class=\"col_heading level0 col1\" >distance</th>\n",
       "      <th id=\"T_d5d88_level0_col2\" class=\"col_heading level0 col2\" >source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d5d88_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d5d88_row0_col0\" class=\"data row0 col0\" >general_78</td>\n",
       "      <td id=\"T_d5d88_row0_col1\" class=\"data row0 col1\" >1.3006</td>\n",
       "      <td id=\"T_d5d88_row0_col2\" class=\"data row0 col2\" >Fine-tune for product 3.\t Address input- and   output-level risks 4.\t Build transparency and  reporting mechanisms in   user interactions Responsible LLM product  development stages 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5d88_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d5d88_row1_col0\" class=\"data row1 col0\" >general_231</td>\n",
       "      <td id=\"T_d5d88_row1_col1\" class=\"data row1 col1\" >1.3463</td>\n",
       "      <td id=\"T_d5d88_row1_col2\" class=\"data row1 col2\" >This is why different layers of  safety mitigations throughout the development  lifecycle are critical for creating high-performing,  responsible products.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5d88_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d5d88_row2_col0\" class=\"data row2 col0\" >general_11</td>\n",
       "      <td id=\"T_d5d88_row2_col1\" class=\"data row2 col1\" >1.3492</td>\n",
       "      <td id=\"T_d5d88_row2_col2\" class=\"data row2 col2\" >Making this technology more widely available for  commercial use will further accelerate product  integrations of LLMs, resulting in economic and  competitive benefits.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5d88_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d5d88_row3_col0\" class=\"data row3 col0\" >general_14</td>\n",
       "      <td id=\"T_d5d88_row3_col1\" class=\"data row3 col1\" >1.3693</td>\n",
       "      <td id=\"T_d5d88_row3_col2\" class=\"data row3 col2\" >Openly releasing these  models consolidates costs and eliminates barriers  to entry, allowing small businesses to leverage  innovations in LLMs to explore and build text- generation use cases.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5d88_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d5d88_row4_col0\" class=\"data row4 col0\" >general_54</td>\n",
       "      <td id=\"T_d5d88_row4_col1\" class=\"data row4 col1\" >1.3731</td>\n",
       "      <td id=\"T_d5d88_row4_col2\" class=\"data row4 col2\" >The following section presents responsible AI  considerations for the different stages of LLM  product development.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fdd28adcf70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "answer = rag.tools.query_similarity(query, limit=5)\n",
    "rag.table_report(answer)\n",
    "\n",
    "# answer = rag.load_source_canonical(query=query, limit=5)\n",
    "\n",
    "# for i in range(answer.num_rows):\n",
    "#     s = answer.slice(i,1)\n",
    "#     print(f\"Id: {s.column('id')[0]}.as_py()\")\n",
    "#     print(f\"Distance: {s.column('distance')[0].as_py()}\")\n",
    "#     print(f\"Answer:\\n{print_wrapped(s.column('source')[0].as_py())}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c279bb8-ca82-4e72-93e4-04903f642a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 4. What are some examples of product-specific fine-tuning for LLMs?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f5c5e th {\n",
       "  font-size: 120%;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_f5c5e .row_heading {\n",
       "  display: none;;\n",
       "}\n",
       "#T_f5c5e  .blank {\n",
       "  display: none;;\n",
       "}\n",
       "#T_f5c5e_row0_col0, #T_f5c5e_row0_col1, #T_f5c5e_row0_col2, #T_f5c5e_row0_col3, #T_f5c5e_row1_col0, #T_f5c5e_row1_col1, #T_f5c5e_row1_col2, #T_f5c5e_row1_col3, #T_f5c5e_row2_col0, #T_f5c5e_row2_col1, #T_f5c5e_row2_col2, #T_f5c5e_row2_col3, #T_f5c5e_row3_col0, #T_f5c5e_row3_col1, #T_f5c5e_row3_col2, #T_f5c5e_row3_col3, #T_f5c5e_row4_col0, #T_f5c5e_row4_col1, #T_f5c5e_row4_col2, #T_f5c5e_row4_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f5c5e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f5c5e_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
       "      <th id=\"T_f5c5e_level0_col1\" class=\"col_heading level0 col1\" >distance</th>\n",
       "      <th id=\"T_f5c5e_level0_col2\" class=\"col_heading level0 col2\" >source</th>\n",
       "      <th id=\"T_f5c5e_level0_col3\" class=\"col_heading level0 col3\" >cross-encoder_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f5c5e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f5c5e_row0_col0\" class=\"data row0 col0\" >general_210</td>\n",
       "      <td id=\"T_f5c5e_row0_col1\" class=\"data row0 col1\" >1.3902</td>\n",
       "      <td id=\"T_f5c5e_row0_col2\" class=\"data row0 col2\" >•\t Control mechanisms: Additional controls could  include giving users the option to customize the  outputs generated by an LLM.</td>\n",
       "      <td id=\"T_f5c5e_row0_col3\" class=\"data row0 col3\" >0.4954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5c5e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f5c5e_row1_col0\" class=\"data row1 col0\" >general_54</td>\n",
       "      <td id=\"T_f5c5e_row1_col1\" class=\"data row1 col1\" >1.3731</td>\n",
       "      <td id=\"T_f5c5e_row1_col2\" class=\"data row1 col2\" >The following section presents responsible AI  considerations for the different stages of LLM  product development.</td>\n",
       "      <td id=\"T_f5c5e_row1_col3\" class=\"data row1 col3\" >0.4736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5c5e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f5c5e_row2_col0\" class=\"data row2 col0\" >general_78</td>\n",
       "      <td id=\"T_f5c5e_row2_col1\" class=\"data row2 col1\" >1.3006</td>\n",
       "      <td id=\"T_f5c5e_row2_col2\" class=\"data row2 col2\" >Fine-tune for product 3.\t Address input- and   output-level risks 4.\t Build transparency and  reporting mechanisms in   user interactions Responsible LLM product  development stages 1</td>\n",
       "      <td id=\"T_f5c5e_row2_col3\" class=\"data row2 col3\" >0.4535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5c5e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f5c5e_row3_col0\" class=\"data row3 col0\" >general_212</td>\n",
       "      <td id=\"T_f5c5e_row3_col1\" class=\"data row3 col1\" >1.3908</td>\n",
       "      <td id=\"T_f5c5e_row3_col2\" class=\"data row3 col2\" >Offering editing capabilities  can also enhance a user’s sense of agency  over outputs, and developers should consider  education flows that can set a user up for  success, such as offering prompt suggestions or  explanations of how to improve an output.  </td>\n",
       "      <td id=\"T_f5c5e_row3_col3\" class=\"data row3 col3\" >0.3574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5c5e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f5c5e_row4_col0\" class=\"data row4 col0\" >general_11</td>\n",
       "      <td id=\"T_f5c5e_row4_col1\" class=\"data row4 col1\" >1.3492</td>\n",
       "      <td id=\"T_f5c5e_row4_col2\" class=\"data row4 col2\" >Making this technology more widely available for  commercial use will further accelerate product  integrations of LLMs, resulting in economic and  competitive benefits.</td>\n",
       "      <td id=\"T_f5c5e_row4_col3\" class=\"data row4 col3\" >0.2586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fdd145cfee0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "answer = rag.tools.query_reranker(query)\n",
    "rag.table_report(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07281b73-a527-47f8-947c-f31931ee49ed",
   "metadata": {},
   "source": [
    "### Tidy up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdc499d-e2c5-4c88-87e6-f6051df849d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag.remove_canonical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d696ab7-b1cf-4e83-be6a-35235af55459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
