{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "962e2eab-fef2-4393-8e03-836e7921a99d",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# saves you having to use print as all exposed variables are printed in the cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116bbfb0-cf0d-4946-a9ab-0430479d0e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warning message\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68bdaf3a-78fb-438b-9590-d4feb46ad151",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.compute as pc\n",
    "from nn_rag import Knowledge, Controller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d62f37-c1fe-4d91-aadc-231253ccf97f",
   "metadata": {},
   "source": [
    "### Chroma Vector Params\n",
    "\n",
    "        URI example in-memory\n",
    "            uri = \"chromadb:///<collection>?reference=<name>\"\n",
    "\n",
    "        params:\n",
    "            collection: The name of the collection\n",
    "            reference: a prefix name to reference the document vector\n",
    "\n",
    "        Environment:\n",
    "            CHROMA_EMBEDDING_QUANTIZE\n",
    "            CHROMA_QUERY_SEARCH_LIMIT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb5c8ff-3497-4213-a0fc-db712cb4a8a8",
   "metadata": {},
   "source": [
    "### Instantiate capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b85ae8c1-598a-4764-97b0-7b882e3fadc8",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "kn = Knowledge.from_env('demo', has_contract=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361cb284-9dbd-461b-9fbe-6abf87fed6c1",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "tbl = kn.set_source_uri(\"./hadron/source/llama-Responsible-Use-Guide.pdf\").load_source_canonical()\n",
    "kn.set_persist_uri('chromadb:///')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7a6dec-cfc8-4d94-9b75-9bb937348452",
   "metadata": {},
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a772c2-695d-4ad5-9c88-35b3b130d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = kn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d00b208-3e72-435c-bdf1-deaa89c8de35",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be78fdc2-df14-4fad-bcf2-60490b6e9629",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KnowledgeIntent' object has no attribute 'text_chunker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[43mkn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_chunker\u001b[49m(sentences, char_chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m300\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KnowledgeIntent' object has no attribute 'text_chunker'"
     ]
    }
   ],
   "source": [
    "chunks = kn.tools.text_chunker(sentences, char_chunk_size='300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caee61a-6506-4025-99d5-d2969a320a10",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caf4977-4398-45f5-9a48-af84a21cf7a7",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "kn.save_persist_canonical(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e792c-5d0a-4d9c-bad0-59e409c18097",
   "metadata": {},
   "source": [
    "----------------\n",
    "## Chroma Vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302065d3-638c-4500-893c-b104c9a2b2d3",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce53daf-dc7c-4632-acd9-44565f1ca542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    return wrapped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5299de0-8f42-4084-a359-fa3d377206d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "questions = [\n",
    "    \"1. What are the core principles of responsible AI mentioned in the guide?\",\n",
    "    \"2. How does Meta's open approach contribute to AI innovation?\",\n",
    "    \"3. What are the stages of responsible LLM product development according to the guide?\",\n",
    "    \"4. What are some examples of product-specific fine-tuning for LLMs?\",\n",
    "    \"5. What considerations should be taken into account when defining content policies for LLMs?\",\n",
    "    \"6. What are the benefits of democratizing access to large language models, as stated in the guide?\"\n",
    "]\n",
    "\n",
    "query = random.choice(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eede9513-fb35-4708-b74d-10ce21e9113a",
   "metadata": {},
   "source": [
    "### Model Answers\n",
    "1. **Core principles of responsible AI:**\n",
    "   The guide outlines core principles of responsible AI, which include fairness and inclusion, robustness and safety, privacy and security, and transparency and control. Additionally, it emphasizes the importance of governance and accountability mechanisms to ensure these principles are upheld throughout the development and deployment of AI systems.\n",
    "\n",
    "2. **Meta's open approach and AI innovation:**\n",
    "   Meta's open approach to AI innovation involves open-sourcing code and datasets, contributing to the AI community's infrastructure, and making large language models available for research. This approach fosters a vibrant AI-innovation ecosystem, driving breakthroughs in various sectors and enabling exploratory research and large-scale production deployment. It also draws upon the collective wisdom and diversity of the AI community to improve and democratize AI technology.\n",
    "\n",
    "3. **Stages of responsible LLM product development:**\n",
    "   The guide identifies four stages of responsible LLM product development: determining the use case, fine-tuning for the product, addressing input- and output-level risks, and building transparency and reporting mechanisms in user interactions. Each stage involves specific considerations and mitigation strategies to ensure the safe and effective deployment of LLM-powered products.\n",
    "\n",
    "4. **Examples of product-specific fine-tuning:**\n",
    "   Product-specific fine-tuning examples provided in the guide include text summarization, question answering, and sentiment analysis. For instance, a pretrained language model can be fine-tuned on a dataset of long-form documents and summaries for text summarization, on a Q&A dataset for answering questions, and on labeled text reviews for sentiment analysis. These examples demonstrate how fine-tuning can tailor a model's capabilities to specific use cases, enhancing performance and applicability.\n",
    "\n",
    "5. **Considerations for defining content policies:**\n",
    "   When defining content policies for LLMs, developers should consider the intended use and audience of their product, legal and safety limitations, and the needs of specific user communities. Content policies should outline allowable content and safety limitations, which will guide data annotation and safety fine-tuning. It is also important to address potential biases in human feedback and data annotation processes to ensure fairness and objectivity.\n",
    "\n",
    "6. **Benefits of democratizing access to large language models:**\n",
    "   Democratizing access to large language models, as discussed in the guide, reduces barriers to entry for small businesses and fosters innovation across various sectors. By making these models widely available, small organizations can leverage advanced AI technology without incurring prohibitive costs, leading to economic growth and a more level playing field. This approach also promotes collaboration and collective improvement of AI models, ensuring that advancements benefit a broader range of users and applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1aaaab-ab57-47a2-884a-b382347bb41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "answer = kn.load_canonical('query', query=query)\n",
    "\n",
    "for i in range(answer.num_rows):\n",
    "    s = answer.slice(i,1)\n",
    "    print(f\"Id: {s.column('id')[0]}.as_py()\")\n",
    "    print(f\"Distance: {s.column('distance')[0].as_py()}\")\n",
    "    print(f\"Answer: {print_wrapped(s.column('source')[0].as_py())}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c279bb8-ca82-4e72-93e4-04903f642a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
