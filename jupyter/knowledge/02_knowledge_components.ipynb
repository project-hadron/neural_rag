{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "962e2eab-fef2-4393-8e03-836e7921a99d",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# saves you having to use print as all exposed variables are printed in the cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116bbfb0-cf0d-4946-a9ab-0430479d0e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warning message\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68bdaf3a-78fb-438b-9590-d4feb46ad151",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.compute as pc\n",
    "from nn_rag import Knowledge, Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d62f37-c1fe-4d91-aadc-231253ccf97f",
   "metadata": {},
   "source": [
    "### Chroma Vector Params\n",
    "\n",
    "        URI example in-memory\n",
    "            uri = \"chromadb:///<collection>?reference=<name>\"\n",
    "\n",
    "        params:\n",
    "            collection: The name of the collection\n",
    "            reference: a prefix name to reference the document vector\n",
    "\n",
    "        Environment:\n",
    "            CHROMA_EMBEDDING_QUANTIZE\n",
    "            CHROMA_QUERY_SEARCH_LIMIT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb5c8ff-3497-4213-a0fc-db712cb4a8a8",
   "metadata": {},
   "source": [
    "### Instantiate capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b85ae8c1-598a-4764-97b0-7b882e3fadc8",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "kn = Knowledge.from_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361cb284-9dbd-461b-9fbe-6abf87fed6c1",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "tbl = kn.set_source_uri(\"./hadron/source/llama-Responsible-Use-Guide.pdf\").load_source_canonical()\n",
    "kn.set_persist_uri('chroma:///')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7a6dec-cfc8-4d94-9b75-9bb937348452",
   "metadata": {},
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30a772c2-695d-4ad5-9c88-35b3b130d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = kn.tools.replace_on_pattern(tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d00b208-3e72-435c-bdf1-deaa89c8de35",
   "metadata": {},
   "source": [
    "### Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be78fdc2-df14-4fad-bcf2-60490b6e9629",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b670765e18b3468a8969f6b5c6564386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating scores:   0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sentence size 777\n",
      "Mean Sentence size 151.13127413127413\n",
      "Min Sentence size 1\n"
     ]
    }
   ],
   "source": [
    "sentences = kn.tools.text_to_sentences(doc, include_score=True, disable_progress_bar=True)\n",
    "print(f\"Max Sentence size {pc.max(sentences['char_count'])}\")\n",
    "print(f\"Mean Sentence size {pc.mean(sentences['char_count'])}\")\n",
    "print(f\"Min Sentence size {pc.min(sentences['char_count'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f79e51-7370-41aa-af8f-06f57f636142",
   "metadata": {},
   "source": [
    "### Threshold similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a160c4c-4cea-4f65-87cd-492055fc5f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold silimarity for [3, 4, 15, 16, 21, 22, 23, 30, 31, 32, 33, 36, 41, 42, 45, 46, 64, 71, 72, 82, 83, 103, 117, 121, 127, 135, 136, 137, 163, 164, 173, 196, 213, 216, 240, 251]\n",
      "Percentile Sentence size [('90%', 343.0), ('95%', 544.0), ('98%', 694.0), ('99%', 722.0)]\n"
     ]
    }
   ],
   "source": [
    "high_similarity = pc.filter(sentences, pc.greater(sentences['score'], 0.95)).column('index').to_pylist()\n",
    "print(f\"Threshold silimarity for {high_similarity}\")\n",
    "\n",
    "sentence_sim = kn.tools.filter_on_join(sentences, indices=high_similarity)\n",
    "percentile_values = pc.quantile(sentence_sim['char_count'], q=[0.9, 0.95, 0.98, 0.99])\n",
    "print(f\"Percentile Sentence size {list(zip(['90%', '95%', '98%', '99%'], pc.round(percentile_values,0).to_pylist()))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce456d2-80e7-4551-a516-81b99be1cd50",
   "metadata": {},
   "source": [
    "### Sentence Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d0f7f78-bd7a-4bea-86f9-aa749efbbbab",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sentence size 768\n",
      "Mean Sentence size 174.0\n",
      "Min Sentence size 1\n"
     ]
    }
   ],
   "source": [
    "sentence_chunks = kn.tools.text_to_chunks(sentence_sim, chunk_size=768, disable_progress_bar=True)\n",
    "print(f\"Max Sentence size {pc.max(sentence_chunks['char_count'])}\")\n",
    "print(f\"Mean Sentence size {pc.round(pc.mean(sentence_chunks['char_count']),0)}\")\n",
    "print(f\"Min Sentence size {pc.min(sentence_chunks['char_count'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01e50a4-97d1-4555-8d6e-cf2e20fe324b",
   "metadata": {},
   "source": [
    "### Sentence Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28473209-f8e9-4fd4-bd8a-6a42dfebc2ad",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentile Sentence size [('0.1%', 198.0), ('1%', 218.0), ('25%', 585.0), ('50%', 670.0)]\n"
     ]
    }
   ],
   "source": [
    "sentence_join = kn.tools.filter_on_join(sentence_chunks, chunk_size=768, disable_progress_bar=True)\n",
    "percentile_values = pc.quantile(sentence_join['char_count'], q=[0.001, 0.01, 0.25, 0.50])\n",
    "print(f\"Percentile Sentence size {list(zip(['0.1%', '1%', '25%', '50%'], pc.round(percentile_values,0).to_pylist()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caee61a-6506-4025-99d5-d2969a320a10",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1caf4977-4398-45f5-9a48-af84a21cf7a7",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "kn.save_persist_canonical(sentence_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e792c-5d0a-4d9c-bad0-59e409c18097",
   "metadata": {},
   "source": [
    "----------------\n",
    "## Chroma Vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302065d3-638c-4500-893c-b104c9a2b2d3",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fce53daf-dc7c-4632-acd9-44565f1ca542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    return wrapped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5299de0-8f42-4084-a359-fa3d377206d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "questions = [\n",
    "    \"1. What are the core principles of responsible AI mentioned in the guide?\",\n",
    "    \"2. How does Meta's open approach contribute to AI innovation?\",\n",
    "    \"3. What are the stages of responsible LLM product development according to the guide?\",\n",
    "    \"4. What are some examples of product-specific fine-tuning for LLMs?\",\n",
    "    \"5. What considerations should be taken into account when defining content policies for LLMs?\",\n",
    "    \"6. What are the benefits of democratizing access to large language models, as stated in the guide?\"\n",
    "]\n",
    "\n",
    "query = random.choice(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eede9513-fb35-4708-b74d-10ce21e9113a",
   "metadata": {},
   "source": [
    "### Model Answers\n",
    "1. **Core principles of responsible AI:**\n",
    "   The guide outlines core principles of responsible AI, which include fairness and inclusion, robustness and safety, privacy and security, and transparency and control. Additionally, it emphasizes the importance of governance and accountability mechanisms to ensure these principles are upheld throughout the development and deployment of AI systems.\n",
    "\n",
    "2. **Meta's open approach and AI innovation:**\n",
    "   Meta's open approach to AI innovation involves open-sourcing code and datasets, contributing to the AI community's infrastructure, and making large language models available for research. This approach fosters a vibrant AI-innovation ecosystem, driving breakthroughs in various sectors and enabling exploratory research and large-scale production deployment. It also draws upon the collective wisdom and diversity of the AI community to improve and democratize AI technology.\n",
    "\n",
    "3. **Stages of responsible LLM product development:**\n",
    "   The guide identifies four stages of responsible LLM product development: determining the use case, fine-tuning for the product, addressing input- and output-level risks, and building transparency and reporting mechanisms in user interactions. Each stage involves specific considerations and mitigation strategies to ensure the safe and effective deployment of LLM-powered products.\n",
    "\n",
    "4. **Examples of product-specific fine-tuning:**\n",
    "   Product-specific fine-tuning examples provided in the guide include text summarization, question answering, and sentiment analysis. For instance, a pretrained language model can be fine-tuned on a dataset of long-form documents and summaries for text summarization, on a Q&A dataset for answering questions, and on labeled text reviews for sentiment analysis. These examples demonstrate how fine-tuning can tailor a model's capabilities to specific use cases, enhancing performance and applicability.\n",
    "\n",
    "5. **Considerations for defining content policies:**\n",
    "   When defining content policies for LLMs, developers should consider the intended use and audience of their product, legal and safety limitations, and the needs of specific user communities. Content policies should outline allowable content and safety limitations, which will guide data annotation and safety fine-tuning. It is also important to address potential biases in human feedback and data annotation processes to ensure fairness and objectivity.\n",
    "\n",
    "6. **Benefits of democratizing access to large language models:**\n",
    "   Democratizing access to large language models, as discussed in the guide, reduces barriers to entry for small businesses and fosters innovation across various sectors. By making these models widely available, small organizations can leverage advanced AI technology without incurring prohibitive costs, leading to economic growth and a more level playing field. This approach also promotes collaboration and collective improvement of AI models, ensuring that advancements benefit a broader range of users and applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fb2448a-c874-42bb-824a-48eb32fa287f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nn_rag.components.retrieval.Retrieval at 0x7fd167c54ac0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag = Retrieval.from_memory()\n",
    "rag.set_source_uri('chroma:///')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d1aaaab-ab57-47a2-884a-b382347bb41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 3. What are the stages of responsible LLM product development according to the guide?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2384f th {\n",
       "  font-size: 120%;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_2384f .row_heading {\n",
       "  display: none;;\n",
       "}\n",
       "#T_2384f  .blank {\n",
       "  display: none;;\n",
       "}\n",
       "#T_2384f_row0_col0, #T_2384f_row0_col1, #T_2384f_row0_col2, #T_2384f_row1_col0, #T_2384f_row1_col1, #T_2384f_row1_col2, #T_2384f_row2_col0, #T_2384f_row2_col1, #T_2384f_row2_col2, #T_2384f_row3_col0, #T_2384f_row3_col1, #T_2384f_row3_col2, #T_2384f_row4_col0, #T_2384f_row4_col1, #T_2384f_row4_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2384f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2384f_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
       "      <th id=\"T_2384f_level0_col1\" class=\"col_heading level0 col1\" >distance</th>\n",
       "      <th id=\"T_2384f_level0_col2\" class=\"col_heading level0 col2\" >source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2384f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_2384f_row0_col0\" class=\"data row0 col0\" >general_58</td>\n",
       "      <td id=\"T_2384f_row0_col1\" class=\"data row0 col1\" >1.2972</td>\n",
       "      <td id=\"T_2384f_row0_col2\" class=\"data row0 col2\" >The final stage is to evaluate the fine-tuned model on a test set to measure its performance on the specific task and against safety benchmarks, according to the use case. This includes analyzing the model’s strengths and weaknesses based on evaluation results, gathering more data to further enhance performance and safety, and iterating until satisfied with the model’s performance using holdout test datasets. There are many complementary types of evaluations that are useful for measuring risks i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2384f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_2384f_row1_col0\" class=\"data row1 col0\" >general_25</td>\n",
       "      <td id=\"T_2384f_row1_col1\" class=\"data row1 col1\" >1.3252</td>\n",
       "      <td id=\"T_2384f_row1_col2\" class=\"data row1 col2\" >In addition to performing a variety of pretraining data-level investigations to help understand the potential capabilities and limitations of our models, we applied considerable safety mitigations to the fine-tuned versions of the model through supervised fine-tuning, reinforcement learning from human feedback (RLHF), and iterative red teaming (these steps are covered further in the section - Fine-tune for product).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2384f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_2384f_row2_col0\" class=\"data row2 col0\" >general_56</td>\n",
       "      <td id=\"T_2384f_row2_col1\" class=\"data row2 col1\" >1.3732</td>\n",
       "      <td id=\"T_2384f_row2_col2\" class=\"data row2 col2\" >n set, and hyperparameters are adjusted as necessary. Fine-tuning an LLM for safety can involve a number of techniques, many of which the research paper on Llama 2 describes in greater depth. These techniques can include: • Supervised Fine-Tuning (SFT): Supervised fine- tuning using data annotated across helpfulness and safety. • Reinforcement Learning from Human Feedback (RLHF) or AI Feedback (RLAIF):</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2384f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_2384f_row3_col0\" class=\"data row3 col0\" >general_77</td>\n",
       "      <td id=\"T_2384f_row3_col1\" class=\"data row3 col1\" >1.3739</td>\n",
       "      <td id=\"T_2384f_row3_col2\" class=\"data row3 col2\" >Classifiers: The more effective, but also more difficult, approach is to develop classifiers that detect and filter outputs based on the meaning conveyed by the words chosen. Classifiers, when properly trained on known examples of a particular sentiment or type of semantic content, can become highly effective at identifying novel instances in which that sentiment or meaning is expressed. Mitigating risks at the output level Based on the downstream use case, you can apply several approaches for d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2384f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_2384f_row4_col0\" class=\"data row4 col0\" >general_75</td>\n",
       "      <td id=\"T_2384f_row4_col1\" class=\"data row4 col1\" >1.3821</td>\n",
       "      <td id=\"T_2384f_row4_col2\" class=\"data row4 col2\" >hus, the safety benefits of such restrictions or modifications should be weighed against those costs, until more robust solutions are developed. Alongside prompts, it might be beneficial to provide instructive sample inputs and outputs that illustrate the desired responsible behavior. 15 JULY 2023 unreasonably restrict the usage of your model.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd167c55930>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "answer = rag.tools.query_similarity(query, limit=5)\n",
    "rag.table_report(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c279bb8-ca82-4e72-93e4-04903f642a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 3. What are the stages of responsible LLM product development according to the guide?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b2d85 th {\n",
       "  font-size: 120%;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_b2d85 .row_heading {\n",
       "  display: none;;\n",
       "}\n",
       "#T_b2d85  .blank {\n",
       "  display: none;;\n",
       "}\n",
       "#T_b2d85_row0_col0, #T_b2d85_row0_col1, #T_b2d85_row0_col2, #T_b2d85_row1_col0, #T_b2d85_row1_col1, #T_b2d85_row1_col2, #T_b2d85_row2_col0, #T_b2d85_row2_col1, #T_b2d85_row2_col2, #T_b2d85_row3_col0, #T_b2d85_row3_col1, #T_b2d85_row3_col2, #T_b2d85_row4_col0, #T_b2d85_row4_col1, #T_b2d85_row4_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b2d85\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b2d85_level0_col0\" class=\"col_heading level0 col0\" >cross-encoder_score</th>\n",
       "      <th id=\"T_b2d85_level0_col1\" class=\"col_heading level0 col1\" >source</th>\n",
       "      <th id=\"T_b2d85_level0_col2\" class=\"col_heading level0 col2\" >id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b2d85_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b2d85_row0_col0\" class=\"data row0 col0\" >0.4792</td>\n",
       "      <td id=\"T_b2d85_row0_col1\" class=\"data row0 col1\" >The fine-tuned LLM itself can be used to create synthetic ranking data for reward model training. Given a model input, response pairs and relevant guidelines, the LLM predicts which response would best follow the guidelines. The synthetic reward modeling data are then used to augment the reward model’s training data. THE RESPONSIBLE FINE-TUNING FLOW training progress is monitored using a validation set, and hyperparameters are adjusted as necessary. Fine-tuning an LLM for safety can involve a nu</td>\n",
       "      <td id=\"T_b2d85_row0_col2\" class=\"data row0 col2\" >general_55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2d85_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b2d85_row1_col0\" class=\"data row1 col0\" >0.4636</td>\n",
       "      <td id=\"T_b2d85_row1_col1\" class=\"data row1 col1\" >st datasets. There are many complementary types of evaluations that are useful for measuring risks in models, including automatic benchmarks, manual annotations by human raters, and evaluations using an LLM itself as a rater. The Holistic Evaluation of Language Models discusses some of the commonly used automatic benchmarks. Evaluation strategies and processes to improve performance can include: • Automatic evaluation leverages automatic benchmarks and classifiers to judge the output with respec</td>\n",
       "      <td id=\"T_b2d85_row1_col2\" class=\"data row1 col2\" >general_59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2d85_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b2d85_row2_col0\" class=\"data row2 col0\" >0.3886</td>\n",
       "      <td id=\"T_b2d85_row2_col1\" class=\"data row2 col1\" > standards. Additionally, the needs of specific user communities should be considered as you design content policies, such as the development of age-appropriate product experiences. Having these policies in place will dictate the data needed, annotation requirements, and goals for safety fine-tuning, including the types of mitigation steps that will be implemented. These policies will be used for labeling data in later stages when using RLHF and in additional product layers, such as making enfor</td>\n",
       "      <td id=\"T_b2d85_row2_col2\" class=\"data row2 col2\" >general_42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2d85_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b2d85_row3_col0\" class=\"data row3 col0\" >0.3864</td>\n",
       "      <td id=\"T_b2d85_row3_col1\" class=\"data row3 col1\" >To yield a product that is optimized for your target use cases, it’s essential to have a consistent set of goals and outcomes that guide each stage of the process. From the data-collection stage to user feedback, be sure to keep your overall goal in mind. •</td>\n",
       "      <td id=\"T_b2d85_row3_col2\" class=\"data row3 col2\" >general_103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2d85_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b2d85_row4_col0\" class=\"data row4 col0\" >0.3460</td>\n",
       "      <td id=\"T_b2d85_row4_col1\" class=\"data row4 col1\" >Information on pretraining data, model architecture and parameters, and pretrained evaluations are contained in the Llama 2 research paper. The paper also describes in further detail the steps to develop the fine-tuned versions, including detailed safety alignment efforts and evaluation results. Additional information is included in the model card accompanying the release.</td>\n",
       "      <td id=\"T_b2d85_row4_col2\" class=\"data row4 col2\" >general_26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd151602500>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "answer = rag.tools.query_reranker(query)\n",
    "rag.table_report(answer, headers='distance', drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07281b73-a527-47f8-947c-f31931ee49ed",
   "metadata": {},
   "source": [
    "### Tidy up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cdc499d-e2c5-4c88-87e6-f6051df849d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag.remove_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d3b9ea-bdff-4988-b814-c4bba7be5f9a",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
