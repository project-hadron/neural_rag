{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "962e2eab-fef2-4393-8e03-836e7921a99d",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# saves you having to use print as all exposed variables are printed in the cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116bbfb0-cf0d-4946-a9ab-0430479d0e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warning message\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68bdaf3a-78fb-438b-9590-d4feb46ad151",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.compute as pc\n",
    "from nn_rag import Knowledge, Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d62f37-c1fe-4d91-aadc-231253ccf97f",
   "metadata": {},
   "source": [
    "### Chroma Vector Params\n",
    "\n",
    "        URI example in-memory\n",
    "            uri = \"chromadb:///<collection>?reference=<name>\"\n",
    "\n",
    "        params:\n",
    "            collection: The name of the collection\n",
    "            reference: a prefix name to reference the document vector\n",
    "\n",
    "        Environment:\n",
    "            CHROMA_EMBEDDING_QUANTIZE\n",
    "            CHROMA_QUERY_SEARCH_LIMIT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb5c8ff-3497-4213-a0fc-db712cb4a8a8",
   "metadata": {},
   "source": [
    "### Instantiate capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b85ae8c1-598a-4764-97b0-7b882e3fadc8",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "kn = Knowledge.from_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361cb284-9dbd-461b-9fbe-6abf87fed6c1",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "tbl = kn.set_source_uri(\"./hadron/source/llama-Responsible-Use-Guide.pdf\").load_source_canonical()\n",
    "kn.set_persist_uri('chroma:///')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7a6dec-cfc8-4d94-9b75-9bb937348452",
   "metadata": {},
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30a772c2-695d-4ad5-9c88-35b3b130d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = kn.tools.replace_on_pattern(tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d00b208-3e72-435c-bdf1-deaa89c8de35",
   "metadata": {},
   "source": [
    "### Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be78fdc2-df14-4fad-bcf2-60490b6e9629",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sentence size 872\n",
      "Mean Sentence size 164.91020408163266\n",
      "Min Sentence size 13\n"
     ]
    }
   ],
   "source": [
    "sentences = kn.tools.text_to_sentences(doc, disable_progress_bar=True)\n",
    "print(f\"Max Sentence size {pc.max(sentences['char_count'])}\")\n",
    "print(f\"Mean Sentence size {pc.mean(sentences['char_count'])}\")\n",
    "print(f\"Min Sentence size {pc.min(sentences['char_count'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce456d2-80e7-4551-a516-81b99be1cd50",
   "metadata": {},
   "source": [
    "### Sentence Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d0f7f78-bd7a-4bea-86f9-aa749efbbbab",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sentence size 500\n",
      "Mean Sentence size 162.99203187250995\n",
      "Min Sentence size 13\n"
     ]
    }
   ],
   "source": [
    "sentence_chunks = kn.tools.text_to_chunks(sentences, chunk_size=500, disable_progress_bar=True)\n",
    "print(f\"Max Sentence size {pc.max(sentence_chunks['char_count'])}\")\n",
    "print(f\"Mean Sentence size {pc.mean(sentence_chunks['char_count'])}\")\n",
    "print(f\"Min Sentence size {pc.min(sentence_chunks['char_count'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01e50a4-97d1-4555-8d6e-cf2e20fe324b",
   "metadata": {},
   "source": [
    "### Sentence Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28473209-f8e9-4fd4-bd8a-6a42dfebc2ad",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sentence size 500\n",
      "Mean Sentence size 410.62\n",
      "Min Sentence size 181\n"
     ]
    }
   ],
   "source": [
    "sentence_join = kn.tools.filter_on_join(sentence_chunks, chunk_size=500, disable_progress_bar=True)\n",
    "print(f\"Max Sentence size {pc.max(sentence_join['char_count'])}\")\n",
    "print(f\"Mean Sentence size {pc.mean(sentence_join['char_count'])}\")\n",
    "print(f\"Min Sentence size {pc.min(sentence_join['char_count'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caee61a-6506-4025-99d5-d2969a320a10",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1caf4977-4398-45f5-9a48-af84a21cf7a7",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "kn.save_persist_canonical(sentence_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e792c-5d0a-4d9c-bad0-59e409c18097",
   "metadata": {},
   "source": [
    "----------------\n",
    "## Chroma Vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302065d3-638c-4500-893c-b104c9a2b2d3",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fce53daf-dc7c-4632-acd9-44565f1ca542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    return wrapped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5299de0-8f42-4084-a359-fa3d377206d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "questions = [\n",
    "    \"1. What are the core principles of responsible AI mentioned in the guide?\",\n",
    "    \"2. How does Meta's open approach contribute to AI innovation?\",\n",
    "    \"3. What are the stages of responsible LLM product development according to the guide?\",\n",
    "    \"4. What are some examples of product-specific fine-tuning for LLMs?\",\n",
    "    \"5. What considerations should be taken into account when defining content policies for LLMs?\",\n",
    "    \"6. What are the benefits of democratizing access to large language models, as stated in the guide?\"\n",
    "]\n",
    "\n",
    "query = random.choice(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eede9513-fb35-4708-b74d-10ce21e9113a",
   "metadata": {},
   "source": [
    "### Model Answers\n",
    "1. **Core principles of responsible AI:**\n",
    "   The guide outlines core principles of responsible AI, which include fairness and inclusion, robustness and safety, privacy and security, and transparency and control. Additionally, it emphasizes the importance of governance and accountability mechanisms to ensure these principles are upheld throughout the development and deployment of AI systems.\n",
    "\n",
    "2. **Meta's open approach and AI innovation:**\n",
    "   Meta's open approach to AI innovation involves open-sourcing code and datasets, contributing to the AI community's infrastructure, and making large language models available for research. This approach fosters a vibrant AI-innovation ecosystem, driving breakthroughs in various sectors and enabling exploratory research and large-scale production deployment. It also draws upon the collective wisdom and diversity of the AI community to improve and democratize AI technology.\n",
    "\n",
    "3. **Stages of responsible LLM product development:**\n",
    "   The guide identifies four stages of responsible LLM product development: determining the use case, fine-tuning for the product, addressing input- and output-level risks, and building transparency and reporting mechanisms in user interactions. Each stage involves specific considerations and mitigation strategies to ensure the safe and effective deployment of LLM-powered products.\n",
    "\n",
    "4. **Examples of product-specific fine-tuning:**\n",
    "   Product-specific fine-tuning examples provided in the guide include text summarization, question answering, and sentiment analysis. For instance, a pretrained language model can be fine-tuned on a dataset of long-form documents and summaries for text summarization, on a Q&A dataset for answering questions, and on labeled text reviews for sentiment analysis. These examples demonstrate how fine-tuning can tailor a model's capabilities to specific use cases, enhancing performance and applicability.\n",
    "\n",
    "5. **Considerations for defining content policies:**\n",
    "   When defining content policies for LLMs, developers should consider the intended use and audience of their product, legal and safety limitations, and the needs of specific user communities. Content policies should outline allowable content and safety limitations, which will guide data annotation and safety fine-tuning. It is also important to address potential biases in human feedback and data annotation processes to ensure fairness and objectivity.\n",
    "\n",
    "6. **Benefits of democratizing access to large language models:**\n",
    "   Democratizing access to large language models, as discussed in the guide, reduces barriers to entry for small businesses and fosters innovation across various sectors. By making these models widely available, small organizations can leverage advanced AI technology without incurring prohibitive costs, leading to economic growth and a more level playing field. This approach also promotes collaboration and collective improvement of AI models, ensuring that advancements benefit a broader range of users and applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fb2448a-c874-42bb-824a-48eb32fa287f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nn_rag.components.retrieval.Retrieval at 0x7fe8b9d42cb0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag = Retrieval.from_memory()\n",
    "rag.set_source_uri('chroma:///')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d1aaaab-ab57-47a2-884a-b382347bb41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 3. What are the stages of responsible LLM product development according to the guide?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_215ce th {\n",
       "  font-size: 120%;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_215ce .row_heading {\n",
       "  display: none;;\n",
       "}\n",
       "#T_215ce  .blank {\n",
       "  display: none;;\n",
       "}\n",
       "#T_215ce_row0_col0, #T_215ce_row0_col1, #T_215ce_row0_col2, #T_215ce_row1_col0, #T_215ce_row1_col1, #T_215ce_row1_col2, #T_215ce_row2_col0, #T_215ce_row2_col1, #T_215ce_row2_col2, #T_215ce_row3_col0, #T_215ce_row3_col1, #T_215ce_row3_col2, #T_215ce_row4_col0, #T_215ce_row4_col1, #T_215ce_row4_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_215ce\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_215ce_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
       "      <th id=\"T_215ce_level0_col1\" class=\"col_heading level0 col1\" >distance</th>\n",
       "      <th id=\"T_215ce_level0_col2\" class=\"col_heading level0 col2\" >source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_215ce_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_215ce_row0_col0\" class=\"data row0 col0\" >general_24</td>\n",
       "      <td id=\"T_215ce_row0_col1\" class=\"data row0 col1\" >1.3252</td>\n",
       "      <td id=\"T_215ce_row0_col2\" class=\"data row0 col2\" >In addition  to performing a variety of pretraining data-level  investigations to help understand the potential  capabilities and limitations of our models, we applied  considerable safety mitigations to the fine-tuned  versions of the model through supervised fine-tuning,  reinforcement learning from human feedback (RLHF),  and iterative red teaming (these steps are covered  further in the section - Fine-tune for product).   </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_215ce_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_215ce_row1_col0\" class=\"data row1 col0\" >general_57</td>\n",
       "      <td id=\"T_215ce_row1_col1\" class=\"data row1 col1\" >1.3318</td>\n",
       "      <td id=\"T_215ce_row1_col2\" class=\"data row1 col2\" >The final stage is to evaluate the fine-tuned model on  a test set to measure its performance on the specific  task and against safety benchmarks, according to  the use case. This includes analyzing the model’s  strengths and weaknesses based on evaluation  results, gathering more data to further enhance  performance and safety, and iterating until satisfied  with the model’s performance using holdout test  datasets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_215ce_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_215ce_row2_col0\" class=\"data row2 col0\" >general_45</td>\n",
       "      <td id=\"T_215ce_row2_col1\" class=\"data row2 col1\" >1.3493</td>\n",
       "      <td id=\"T_215ce_row2_col2\" class=\"data row2 col2\" >To mitigate these  risks, carefully design the fine-tuning process by  curating a high-quality dataset that is representative  of your use case, conduct rigorous evaluations, and  test your fine-tuned model’s potential use via red  teaming (covered in step four - Evaluate and   improve performance). STEP 3: TRAIN THE MODEL  Fine-tuning involves training the model for a limited  number of iterations.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_215ce_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_215ce_row3_col0\" class=\"data row3 col0\" >general_33</td>\n",
       "      <td id=\"T_215ce_row3_col1\" class=\"data row3 col1\" >1.3679</td>\n",
       "      <td id=\"T_215ce_row3_col2\" class=\"data row3 col2\" >Developing or adopting an internal risk  assessment process can help identify potential  risks for a specific use case and should focus on  how your product’s end users and others could be  affected. This understanding is critical for evaluating  in-context safety for your product deployment, and  can take forms such as surveys and interviews of  potential users or market analysis of similar product  applications.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_215ce_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_215ce_row4_col0\" class=\"data row4 col0\" >general_96</td>\n",
       "      <td id=\"T_215ce_row4_col1\" class=\"data row4 col1\" >1.3709</td>\n",
       "      <td id=\"T_215ce_row4_col2\" class=\"data row4 col2\" >This is why different layers of  safety mitigations throughout the development  lifecycle are critical for creating high-performing,  responsible products. •\t Alignment of objectives at each stage of  development. To yield a product that is optimized  for your target use cases, it’s essential to have  a consistent set of goals and outcomes that  guide each stage of the process. From the  data-collection stage to user feedback, be sure to  keep your overall goal in mind.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe8b9d43a60>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "answer = rag.tools.query_similarity(query, limit=5)\n",
    "rag.table_report(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c279bb8-ca82-4e72-93e4-04903f642a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 3. What are the stages of responsible LLM product development according to the guide?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7b640 th {\n",
       "  font-size: 120%;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_7b640 .row_heading {\n",
       "  display: none;;\n",
       "}\n",
       "#T_7b640  .blank {\n",
       "  display: none;;\n",
       "}\n",
       "#T_7b640_row0_col0, #T_7b640_row0_col1, #T_7b640_row0_col2, #T_7b640_row1_col0, #T_7b640_row1_col1, #T_7b640_row1_col2, #T_7b640_row2_col0, #T_7b640_row2_col1, #T_7b640_row2_col2, #T_7b640_row3_col0, #T_7b640_row3_col1, #T_7b640_row3_col2, #T_7b640_row4_col0, #T_7b640_row4_col1, #T_7b640_row4_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7b640\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7b640_level0_col0\" class=\"col_heading level0 col0\" >source</th>\n",
       "      <th id=\"T_7b640_level0_col1\" class=\"col_heading level0 col1\" >id</th>\n",
       "      <th id=\"T_7b640_level0_col2\" class=\"col_heading level0 col2\" >cross-encoder_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7b640_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7b640_row0_col0\" class=\"data row0 col0\" >At various points in the product development  lifecycle, developers make decisions that shape the  objectives and functionality of the feature, which can  introduce potential risks. These decision points also  provide opportunities to mitigate potential risks.    It is critical that developers examine each layer of the  product to determine which potential risks may arise  based on the product objectives and design,   and implement mitigation strategies accordingly.</td>\n",
       "      <td id=\"T_7b640_row0_col1\" class=\"data row0 col1\" >general_22</td>\n",
       "      <td id=\"T_7b640_row0_col2\" class=\"data row0 col2\" >0.5351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b640_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7b640_row1_col0\" class=\"data row1 col0\" >This is why different layers of  safety mitigations throughout the development  lifecycle are critical for creating high-performing,  responsible products. •\t Alignment of objectives at each stage of  development. To yield a product that is optimized  for your target use cases, it’s essential to have  a consistent set of goals and outcomes that  guide each stage of the process. From the  data-collection stage to user feedback, be sure to  keep your overall goal in mind.</td>\n",
       "      <td id=\"T_7b640_row1_col1\" class=\"data row1 col1\" >general_96</td>\n",
       "      <td id=\"T_7b640_row1_col2\" class=\"data row1 col2\" >0.4827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b640_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7b640_row2_col0\" class=\"data row2 col0\" >There are many complementary types of evaluations  that are useful for measuring risks in models,  including automatic benchmarks, manual annotations  by human raters, and evaluations using an LLM  itself as a rater. The Holistic Evaluation of Language  Models discusses some of the commonly used  automatic benchmarks.     </td>\n",
       "      <td id=\"T_7b640_row2_col1\" class=\"data row2 col1\" >general_58</td>\n",
       "      <td id=\"T_7b640_row2_col2\" class=\"data row2 col2\" >0.4608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b640_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7b640_row3_col0\" class=\"data row3 col0\" >ent stages\t \t \t 7 \t Determine use case\t \t \t \t \t \t 7 \t Fine-tune for product \t \t \t \t \t \t 8 \t \t The responsible fine-tuning flow \t \t \t \t 9 \t \t Step 1: Define content policies & mitigations\t \t \t 9 \t \t Step 2: Prepare data\t \t \t \t \t \t 10 \t \t Step 3: Train the model \t \t \t \t \t 10 \t Reinforcement Learning from Human Feedback (RLHF)\t                 11 \t Reinforcement Learning from AI Feedback (RLAIF)\t                 11 \t \t Step 4: Evaluate and improve performance \t \t \t 12 \t </td>\n",
       "      <td id=\"T_7b640_row3_col1\" class=\"data row3 col1\" >general_1</td>\n",
       "      <td id=\"T_7b640_row3_col2\" class=\"data row3 col2\" >0.4256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b640_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7b640_row4_col0\" class=\"data row4 col0\" >Information on pretraining data, model architecture  and parameters, and pretrained evaluations are  contained in the Llama 2 research paper. The  paper also describes in further detail the steps to  develop the fine-tuned versions, including detailed  safety alignment efforts and evaluation results.   Additional information is included in the model card  accompanying the release.</td>\n",
       "      <td id=\"T_7b640_row4_col1\" class=\"data row4 col1\" >general_25</td>\n",
       "      <td id=\"T_7b640_row4_col2\" class=\"data row4 col2\" >0.4162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe8a5aaa9e0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "answer = rag.tools.query_reranker(query)\n",
    "rag.table_report(answer, headers='distance', drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07281b73-a527-47f8-947c-f31931ee49ed",
   "metadata": {},
   "source": [
    "### Tidy up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cdc499d-e2c5-4c88-87e6-f6051df849d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag.remove_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d3b9ea-bdff-4988-b814-c4bba7be5f9a",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
