{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "962e2eab-fef2-4393-8e03-836e7921a99d",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# saves you having to use print as all exposed variables are printed in the cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116bbfb0-cf0d-4946-a9ab-0430479d0e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warning message\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68bdaf3a-78fb-438b-9590-d4feb46ad151",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.compute as pc\n",
    "from nn_rag import Knowledge, Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d62f37-c1fe-4d91-aadc-231253ccf97f",
   "metadata": {},
   "source": [
    "### Chroma Vector Params\n",
    "\n",
    "        URI example in-memory\n",
    "            uri = \"chromadb:///<collection>?reference=<name>\"\n",
    "        URI example to file\n",
    "                uri = \"chromadb:///<path>/<collection>?reference=<name>\"\n",
    "\n",
    "        params:\n",
    "            collection: The name of the collection\n",
    "            reference: a prefix name to reference the document vector\n",
    "\n",
    "        Environment:\n",
    "            CHROMA_EMBEDDING_QUANTIZE\n",
    "            CHROMA_QUERY_SEARCH_LIMIT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb5c8ff-3497-4213-a0fc-db712cb4a8a8",
   "metadata": {},
   "source": [
    "### Instantiate capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b85ae8c1-598a-4764-97b0-7b882e3fadc8",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "kn = Knowledge.from_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361cb284-9dbd-461b-9fbe-6abf87fed6c1",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# tbl = kn.set_source_uri(\"./hadron/source/llama-Responsible-Use-Guide.pdf\").load_source_canonical()\n",
    "tbl = kn.set_source_uri(\"https://raw.githubusercontent.com/meta-llama/llama/main/Responsible-Use-Guide.pdf\").load_source_canonical()\n",
    "kn.set_persist_uri('chroma:///hadron/data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7a6dec-cfc8-4d94-9b75-9bb937348452",
   "metadata": {},
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30a772c2-695d-4ad5-9c88-35b3b130d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = kn.tools.replace_on_pattern(tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d00b208-3e72-435c-bdf1-deaa89c8de35",
   "metadata": {},
   "source": [
    "### Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e72871ab-8749-4586-8510-c35516a62c78",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516919d6322441328baffd088d837ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "building sentences:   0%|          | 0/6709 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = kn.tools.text_to_sentences(doc, include_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4595a22a-1098-4b44-afa8-5032e2ba230f",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sentence Size 777\n",
      "Percentile Sentence Size [('1%', 1.0), ('25%', 97.0), ('50%', 137.0), ('75%', 192.0), ('99%', 502.0)]\n",
      "Min Sentence Size 1\n",
      "\n",
      "Percentile Similarity Score [('99%', 0.0), ('99.5%', 0.0), ('99.9%', 0.0), ('99.98%', 0.0)]\n",
      "Max Similarity Score 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max Sentence Size {pc.max(sentences['char_count'])}\")\n",
    "percentile_values = pc.quantile(sentences['char_count'], q=[0.01, 0.25, 0.5, 0.75, 0.99])\n",
    "print(f\"Percentile Sentence Size {list(zip(['1%', '25%', '50%', '75%', '99%'], pc.round(percentile_values,0).to_pylist()))}\")\n",
    "print(f\"Min Sentence Size {pc.min(sentences['char_count'])}\")\n",
    "print('')\n",
    "percentile_values = pc.quantile(sentences['score'], q=[0.99, 0.995, 0.999, 0.9998])\n",
    "print(f\"Percentile Similarity Score {list(zip(['99%', '99.5%', '99.9%', '99.98%'], pc.round(percentile_values,3).to_pylist()))}\")\n",
    "print(f\"Max Similarity Score {pc.round(pc.max(sentences['score']),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f79e51-7370-41aa-af8f-06f57f636142",
   "metadata": {},
   "source": [
    "### Threshold Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a160c4c-4cea-4f65-87cd-492055fc5f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold silimarity for []\n",
      "Percentile Sentence size [('90%', 249.0), ('95%', 285.0), ('98%', 438.0), ('99%', 502.0)]\n"
     ]
    }
   ],
   "source": [
    "high_similarity = pc.filter(sentences, pc.greater(sentences['score'], 0.80)).column('index').to_pylist()\n",
    "print(f\"Threshold silimarity for {high_similarity}\")\n",
    "\n",
    "sentences_sim = kn.tools.filter_on_join(sentences, indices=high_similarity)\n",
    "percentile_values = pc.quantile(sentences_sim['char_count'], q=[0.9, 0.95, 0.98, 0.99])\n",
    "print(f\"Percentile Sentence size {list(zip(['90%', '95%', '98%', '99%'], pc.round(percentile_values,0).to_pylist()))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ad22e5-56e9-4a10-a787-3578a763733c",
   "metadata": {},
   "source": [
    "### Remove Short Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae3b674a-766c-488a-9ac7-2764a372f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_trim = kn.tools.filter_on_condition(sentences_sim, header='char_count', condition=[(5, 'less', None)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5201a68-5e38-4e7c-afbd-46500de28b4b",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sentence Size 777\n",
      "Percentile Sentence Size [('1%', 19.35), ('25%', 100.25), ('50%', 142.0), ('75%', 192.75), ('99%', 507.95)]\n",
      "Min Sentence Size 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max Sentence Size {pc.max(sentences_trim['char_count'])}\")\n",
    "percentile_values = pc.quantile(sentences_trim['char_count'], q=[0.01, 0.25, 0.5, 0.75, 0.99])\n",
    "print(f\"Percentile Sentence Size {list(zip(['1%', '25%', '50%', '75%', '99%'], pc.round(percentile_values,3).to_pylist()))}\")\n",
    "print(f\"Min Sentence Size {pc.min(sentences_trim['char_count'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce456d2-80e7-4551-a516-81b99be1cd50",
   "metadata": {},
   "source": [
    "### Sentence Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a442d391-dc5f-4d04-a8bf-35e126509377",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f843ba79b474234a885a0e65284874f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "building chunks:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_chunks = kn.tools.text_to_chunks(sentences_trim, chunk_size=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b08d931-1ea4-443e-a310-f222799b7524",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sentence size 768\n",
      "Mean Sentence size 159.0\n",
      "Min Sentence size 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max Sentence size {pc.max(sentence_chunks['char_count'])}\")\n",
    "print(f\"Mean Sentence size {pc.round(pc.mean(sentence_chunks['char_count']),0)}\")\n",
    "print(f\"Min Sentence size {pc.min(sentence_chunks['char_count'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01e50a4-97d1-4555-8d6e-cf2e20fe324b",
   "metadata": {},
   "source": [
    "### Sentence Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28473209-f8e9-4fd4-bd8a-6a42dfebc2ad",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentile Sentence size [('0.1%', 407.0), ('1%', 426.0), ('25%', 630.0), ('50%', 690.0)]\n"
     ]
    }
   ],
   "source": [
    "sentence_join = kn.tools.filter_on_join(sentence_chunks, chunk_size=768)\n",
    "percentile_values = pc.quantile(sentence_join['char_count'], q=[0.001, 0.01, 0.25, 0.50])\n",
    "print(f\"Percentile Sentence size {list(zip(['0.1%', '1%', '25%', '50%'], pc.round(percentile_values,0).to_pylist()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caee61a-6506-4025-99d5-d2969a320a10",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1caf4977-4398-45f5-9a48-af84a21cf7a7",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "kn.save_persist_canonical(sentence_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e792c-5d0a-4d9c-bad0-59e409c18097",
   "metadata": {},
   "source": [
    "----------------\n",
    "## Chroma Vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302065d3-638c-4500-893c-b104c9a2b2d3",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fce53daf-dc7c-4632-acd9-44565f1ca542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    return wrapped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5299de0-8f42-4084-a359-fa3d377206d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "questions = [\n",
    "    \"1. What are the core principles of responsible AI mentioned in the guide?\",\n",
    "    \"2. How does Meta's open approach contribute to AI innovation?\",\n",
    "    \"3. What are the stages of responsible LLM product development according to the guide?\",\n",
    "    \"4. What are some examples of product-specific fine-tuning for LLMs?\",\n",
    "    \"5. What considerations should be taken into account when defining content policies for LLMs?\",\n",
    "    \"6. What are the benefits of democratizing access to large language models, as stated in the guide?\"\n",
    "]\n",
    "\n",
    "query = random.choice(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eede9513-fb35-4708-b74d-10ce21e9113a",
   "metadata": {},
   "source": [
    "### Model Answers\n",
    "1. **Core principles of responsible AI:**\n",
    "   The guide outlines core principles of responsible AI, which include fairness and inclusion, robustness and safety, privacy and security, and transparency and control. Additionally, it emphasizes the importance of governance and accountability mechanisms to ensure these principles are upheld throughout the development and deployment of AI systems.\n",
    "\n",
    "2. **Meta's open approach and AI innovation:**\n",
    "   Meta's open approach to AI innovation involves open-sourcing code and datasets, contributing to the AI community's infrastructure, and making large language models available for research. This approach fosters a vibrant AI-innovation ecosystem, driving breakthroughs in various sectors and enabling exploratory research and large-scale production deployment. It also draws upon the collective wisdom and diversity of the AI community to improve and democratize AI technology.\n",
    "\n",
    "3. **Stages of responsible LLM product development:**\n",
    "   The guide identifies four stages of responsible LLM product development: determining the use case, fine-tuning for the product, addressing input- and output-level risks, and building transparency and reporting mechanisms in user interactions. Each stage involves specific considerations and mitigation strategies to ensure the safe and effective deployment of LLM-powered products.\n",
    "\n",
    "4. **Examples of product-specific fine-tuning:**\n",
    "   Product-specific fine-tuning examples provided in the guide include text summarization, question answering, and sentiment analysis. For instance, a pretrained language model can be fine-tuned on a dataset of long-form documents and summaries for text summarization, on a Q&A dataset for answering questions, and on labeled text reviews for sentiment analysis. These examples demonstrate how fine-tuning can tailor a model's capabilities to specific use cases, enhancing performance and applicability.\n",
    "\n",
    "5. **Considerations for defining content policies:**\n",
    "   When defining content policies for LLMs, developers should consider the intended use and audience of their product, legal and safety limitations, and the needs of specific user communities. Content policies should outline allowable content and safety limitations, which will guide data annotation and safety fine-tuning. It is also important to address potential biases in human feedback and data annotation processes to ensure fairness and objectivity.\n",
    "\n",
    "6. **Benefits of democratizing access to large language models:**\n",
    "   Democratizing access to large language models, as discussed in the guide, reduces barriers to entry for small businesses and fosters innovation across various sectors. By making these models widely available, small organizations can leverage advanced AI technology without incurring prohibitive costs, leading to economic growth and a more level playing field. This approach also promotes collaboration and collective improvement of AI models, ensuring that advancements benefit a broader range of users and applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fb2448a-c874-42bb-824a-48eb32fa287f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nn_rag.components.retrieval.Retrieval at 0x7fc1a10eabc0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag = Retrieval.from_memory()\n",
    "rag.set_source_uri('chroma:///hadron/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d1aaaab-ab57-47a2-884a-b382347bb41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 3. What are the stages of responsible LLM product development according to the guide?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0f545 th {\n",
       "  font-size: 120%;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_0f545 .row_heading {\n",
       "  display: none;;\n",
       "}\n",
       "#T_0f545  .blank {\n",
       "  display: none;;\n",
       "}\n",
       "#T_0f545_row0_col0, #T_0f545_row0_col1, #T_0f545_row0_col2, #T_0f545_row1_col0, #T_0f545_row1_col1, #T_0f545_row1_col2, #T_0f545_row2_col0, #T_0f545_row2_col1, #T_0f545_row2_col2, #T_0f545_row3_col0, #T_0f545_row3_col1, #T_0f545_row3_col2, #T_0f545_row4_col0, #T_0f545_row4_col1, #T_0f545_row4_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0f545\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0f545_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
       "      <th id=\"T_0f545_level0_col1\" class=\"col_heading level0 col1\" >distance</th>\n",
       "      <th id=\"T_0f545_level0_col2\" class=\"col_heading level0 col2\" >source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0f545_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0f545_row0_col0\" class=\"data row0 col0\" >general_15</td>\n",
       "      <td id=\"T_0f545_row0_col1\" class=\"data row0 col1\" >1.3260</td>\n",
       "      <td id=\"T_0f545_row0_col2\" class=\"data row0 col2\" >In addition to performing a variety of pretraining data-level investigations to help understand the potential capabilities and limitations of our models, we applied considerable safety mitigations to the fine-tuned versions of the model through supervised fine-tuning, reinforcement learning from human feedback (RLHF), and iterative red teaming (these steps are covered further in the section - Fine-tune for product). Information on pretraining data, model architecture and parameters, and pretrained evaluations are contained in the Llama 2 research paper. The paper also describes in further detail the steps to develop the fine-tuned versions, including detailed safety alignment efforts and evaluation results.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0f545_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_0f545_row1_col0\" class=\"data row1 col0\" >general_56</td>\n",
       "      <td id=\"T_0f545_row1_col1\" class=\"data row1 col1\" >1.3865</td>\n",
       "      <td id=\"T_0f545_row1_col2\" class=\"data row1 col2\" >Here are some key considerations for implementing these components in unison: • Holistic optimization. Although each component has a specific role and optimization goal, components are not isolated entities. Over- optimization of one component without considering its interaction with others can lead to suboptimal outcomes. For instance, over- filtering training data for safety might make later fine-tuning less effective, as the model may not recognize and handle unsafe content appropriately. This is why different layers of safety mitigations throughout the development lifecycle are critical for creating high-performing, responsible products. • Alignment of objectives at each stage of development.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0f545_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_0f545_row2_col0\" class=\"data row2 col0\" >general_34</td>\n",
       "      <td id=\"T_0f545_row2_col1\" class=\"data row2 col1\" >1.3887</td>\n",
       "      <td id=\"T_0f545_row2_col2\" class=\"data row2 col2\" >There are many complementary types of evaluations that are useful for measuring risks in models, including automatic benchmarks, manual annotations by human raters, and evaluations using an LLM itself as a rater. The Holistic Evaluation of Language Models discusses some of the commonly used automatic benchmarks. Evaluation strategies and processes to improve performance can include: • Automatic evaluation leverages automatic benchmarks and classifiers to judge the output with respect to a specific category of risk. Manual evaluation leverages human annotators or subject matter experts to judge the model’s output.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0f545_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_0f545_row3_col0\" class=\"data row3 col0\" >general_27</td>\n",
       "      <td id=\"T_0f545_row3_col1\" class=\"data row3 col1\" >1.3968</td>\n",
       "      <td id=\"T_0f545_row3_col2\" class=\"data row3 col2\" >To mitigate these risks, carefully design the fine-tuning process by curating a high-quality dataset that is representative of your use case, conduct rigorous evaluations, and test your fine-tuned model’s potential use via red teaming (covered in step four - Evaluate and improve performance). STEP 3: TRAIN THE MODEL Fine-tuning involves training the model for a limited number of iterations. Once a pretrained model is loaded in the environment for fine-tuning, the training process involves setting up hyperparameters like epochs, batch size, and learning rate. The data are passed through the model, loss is computed, and weights are updated through backpropagation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0f545_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_0f545_row4_col0\" class=\"data row4 col0\" >general_20</td>\n",
       "      <td id=\"T_0f545_row4_col1\" class=\"data row4 col1\" >1.3993</td>\n",
       "      <td id=\"T_0f545_row4_col2\" class=\"data row4 col2\" >If you’re a developer who is not certain of a particular use case for which you would want to use the model, consider focusing on use cases that improve the lives of people and society, taking into consideration different ethical principles and values. Developing or adopting an internal risk assessment process can help identify potential risks for a specific use case and should focus on how your product’s end users and others could be affected. This understanding is critical for evaluating in-context safety for your product deployment, and can take forms such as surveys and interviews of potential users or market analysis of similar product applications.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc1a10eac20>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "answer = rag.tools.query_similarity(query, limit=5)\n",
    "rag.table_report(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c279bb8-ca82-4e72-93e4-04903f642a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 3. What are the stages of responsible LLM product development according to the guide?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b826a th {\n",
       "  font-size: 120%;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_b826a .row_heading {\n",
       "  display: none;;\n",
       "}\n",
       "#T_b826a  .blank {\n",
       "  display: none;;\n",
       "}\n",
       "#T_b826a_row0_col0, #T_b826a_row0_col1, #T_b826a_row0_col2, #T_b826a_row1_col0, #T_b826a_row1_col1, #T_b826a_row1_col2, #T_b826a_row2_col0, #T_b826a_row2_col1, #T_b826a_row2_col2, #T_b826a_row3_col0, #T_b826a_row3_col1, #T_b826a_row3_col2, #T_b826a_row4_col0, #T_b826a_row4_col1, #T_b826a_row4_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b826a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b826a_level0_col0\" class=\"col_heading level0 col0\" >cross-encoder_score</th>\n",
       "      <th id=\"T_b826a_level0_col1\" class=\"col_heading level0 col1\" >id</th>\n",
       "      <th id=\"T_b826a_level0_col2\" class=\"col_heading level0 col2\" >source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b826a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b826a_row0_col0\" class=\"data row0 col0\" >0.5686</td>\n",
       "      <td id=\"T_b826a_row0_col1\" class=\"data row0 col1\" >general_34</td>\n",
       "      <td id=\"T_b826a_row0_col2\" class=\"data row0 col2\" >There are many complementary types of evaluations that are useful for measuring risks in models, including automatic benchmarks, manual annotations by human raters, and evaluations using an LLM itself as a rater. The Holistic Evaluation of Language Models discusses some of the commonly used automatic benchmarks. Evaluation strategies and processes to improve performance can include: • Automatic evaluation leverages automatic benchmarks and classifiers to judge the output with respect to a specific category of risk. Manual evaluation leverages human annotators or subject matter experts to judge the model’s output.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b826a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b826a_row1_col0\" class=\"data row1 col0\" >0.5665</td>\n",
       "      <td id=\"T_b826a_row1_col1\" class=\"data row1 col1\" >general_14</td>\n",
       "      <td id=\"T_b826a_row1_col2\" class=\"data row1 col2\" >It is critical that developers examine each layer of the product to determine which potential risks may arise based on the product objectives and design, and implement mitigation strategies accordingly. The following section presents responsible AI considerations for the different stages of LLM product development. At each of these levels, we highlight best practices for mitigating potential risks. 5 JULY 2023 Llama 2 is a new version of the Llama 1 model, which was made available previously for research. The new pretrained and fine-tuned versions of the model have been updated for commercial release.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b826a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b826a_row2_col0\" class=\"data row2 col0\" >0.5249</td>\n",
       "      <td id=\"T_b826a_row2_col1\" class=\"data row2 col1\" >general_18</td>\n",
       "      <td id=\"T_b826a_row2_col2\" class=\"data row2 col2\" >If you have terms of service or other relevant policies that apply to how individuals may interact with your LLM, you may wish to fine-tune your model to be aligned with those policies. It may also be necessary to establish new terms of service and policies specific to LLMs, or notify users about how their data or feedback provided will be used in fine-tuning. Development of the foundation model 6 JULY 2023 Developers will identify a specific product use case for the released model, and are responsible for assessing risks associated with that use case and applying best practices to ensure safety. This section outlines the considerations and mitigation strategies available at each stage of product development and deployment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b826a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b826a_row3_col0\" class=\"data row3 col0\" >0.5078</td>\n",
       "      <td id=\"T_b826a_row3_col1\" class=\"data row3 col1\" >general_8</td>\n",
       "      <td id=\"T_b826a_row3_col2\" class=\"data row3 col2\" >Decisions to implement best practices should be evaluated based on the jurisdiction where your products will be deployed and should follow your company’s internal legal and risk management processes. How to use this guide This guide is a resource for developers that outlines common approaches to building responsibly at each level of an LLM-powered product. It covers best practices and considerations that developers should evaluate in the context of their specific use case and market. It also highlights some mitigation strategies and resources available to developers to address risks at various points in the system. These best practices should be considered holistically because strategies adopted at one level can impact the entire system.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b826a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b826a_row4_col0\" class=\"data row4 col0\" >0.4734</td>\n",
       "      <td id=\"T_b826a_row4_col1\" class=\"data row4 col1\" >general_32</td>\n",
       "      <td id=\"T_b826a_row4_col2\" class=\"data row4 col2\" >The synthetic reward modeling data are then used to augment the reward model’s training data. THE RESPONSIBLE FINE-TUNING FLOW training progress is monitored using a validation set, and hyperparameters are adjusted as necessary. Fine-tuning an LLM for safety can involve a number of techniques, many of which the research paper on Llama 2 describes in greater depth. These techniques can include: • Supervised Fine-Tuning (SFT): Supervised fine- tuning using data annotated across helpfulness and safety. • Reinforcement Learning from Human Feedback (RLHF) or AI Feedback (RLAIF): Training safety and helpfulness reward models to support RLHF techniques iteratively improves models and makes them more robust to jailbreaking techniques.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc1ccbadf90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "answer = rag.tools.query_reranker(query)\n",
    "rag.table_report(answer, headers='distance', drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07281b73-a527-47f8-947c-f31931ee49ed",
   "metadata": {},
   "source": [
    "### Tidy up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cdc499d-e2c5-4c88-87e6-f6051df849d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag.remove_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d3b9ea-bdff-4988-b814-c4bba7be5f9a",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
