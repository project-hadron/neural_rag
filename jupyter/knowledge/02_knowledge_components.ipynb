{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "962e2eab-fef2-4393-8e03-836e7921a99d",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# saves you having to use print as all exposed variables are printed in the cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116bbfb0-cf0d-4946-a9ab-0430479d0e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warning message\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68bdaf3a-78fb-438b-9590-d4feb46ad151",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.compute as pc\n",
    "from nn_rag import Knowledge, Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d62f37-c1fe-4d91-aadc-231253ccf97f",
   "metadata": {},
   "source": [
    "### Chroma Vector Params\n",
    "\n",
    "        URI example in-memory\n",
    "            uri = \"chromadb:///<collection>?reference=<name>\"\n",
    "\n",
    "        params:\n",
    "            collection: The name of the collection\n",
    "            reference: a prefix name to reference the document vector\n",
    "\n",
    "        Environment:\n",
    "            CHROMA_EMBEDDING_QUANTIZE\n",
    "            CHROMA_QUERY_SEARCH_LIMIT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb5c8ff-3497-4213-a0fc-db712cb4a8a8",
   "metadata": {},
   "source": [
    "### Instantiate capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b85ae8c1-598a-4764-97b0-7b882e3fadc8",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "kn = Knowledge.from_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361cb284-9dbd-461b-9fbe-6abf87fed6c1",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "tbl = kn.set_source_uri(\"./hadron/source/llama-Responsible-Use-Guide.pdf\").load_source_canonical()\n",
    "kn.set_persist_uri('chroma:///')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7a6dec-cfc8-4d94-9b75-9bb937348452",
   "metadata": {},
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30a772c2-695d-4ad5-9c88-35b3b130d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = kn.tools.replace_on_pattern(tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d00b208-3e72-435c-bdf1-deaa89c8de35",
   "metadata": {},
   "source": [
    "### Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be78fdc2-df14-4fad-bcf2-60490b6e9629",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53e858dfe474b7f85b432d1b8de1e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "building sentences:   0%|          | 0/7586 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc432f7cfda445a928306240ccf941e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build sentences:   0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sentence size 872\n",
      "Mean Sentence size 405.49\n",
      "Min Sentence size 0\n"
     ]
    }
   ],
   "source": [
    "sentences = kn.tools.text_to_sentences(doc, disable_progress_bar=True)\n",
    "print(f\"Max Sentence size {pc.max(sentence_join['char_count'])}\")\n",
    "print(f\"Mean Sentence size {pc.mean(sentence_join['char_count'])}\")\n",
    "print(f\"Min Sentence size {pc.min(sentence_join['char_count'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce456d2-80e7-4551-a516-81b99be1cd50",
   "metadata": {},
   "source": [
    "### Sentence Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d0f7f78-bd7a-4bea-86f9-aa749efbbbab",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53e858dfe474b7f85b432d1b8de1e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "building sentences:   0%|          | 0/7586 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc432f7cfda445a928306240ccf941e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build sentences:   0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sentence size 872\n",
      "Mean Sentence size 405.49\n",
      "Min Sentence size 0\n"
     ]
    }
   ],
   "source": [
    "sentences = kn.tools.text_to_sentences(doc, disable_progress_bar=True)\n",
    "sentence_join = kn.tools.filter_on_join(sentences, chunk_size=500)\n",
    "print(f\"Max Sentence size {pc.max(sentence_join['char_count'])}\")\n",
    "print(f\"Mean Sentence size {pc.mean(sentence_join['char_count'])}\")\n",
    "print(f\"Min Sentence size {pc.min(sentence_join['char_count'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06a6c5fd-3f48-4c1d-a1e7-12c42997dba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max chunk size 500\n",
      "Min chunk size 52\n"
     ]
    }
   ],
   "source": [
    "chunks = kn.tools.text_to_chunks(sentence_join, char_chunk_size=500)\n",
    "print(f\"Max chunk size {pc.max(chunks['char_count'])}\")\n",
    "print(f\"Min chunk size {pc.min(chunks['char_count'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caee61a-6506-4025-99d5-d2969a320a10",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1caf4977-4398-45f5-9a48-af84a21cf7a7",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "kn.save_persist_canonical(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e792c-5d0a-4d9c-bad0-59e409c18097",
   "metadata": {},
   "source": [
    "----------------\n",
    "## Chroma Vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302065d3-638c-4500-893c-b104c9a2b2d3",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fce53daf-dc7c-4632-acd9-44565f1ca542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    return wrapped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5299de0-8f42-4084-a359-fa3d377206d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "questions = [\n",
    "    \"1. What are the core principles of responsible AI mentioned in the guide?\",\n",
    "    \"2. How does Meta's open approach contribute to AI innovation?\",\n",
    "    \"3. What are the stages of responsible LLM product development according to the guide?\",\n",
    "    \"4. What are some examples of product-specific fine-tuning for LLMs?\",\n",
    "    \"5. What considerations should be taken into account when defining content policies for LLMs?\",\n",
    "    \"6. What are the benefits of democratizing access to large language models, as stated in the guide?\"\n",
    "]\n",
    "\n",
    "query = random.choice(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eede9513-fb35-4708-b74d-10ce21e9113a",
   "metadata": {},
   "source": [
    "### Model Answers\n",
    "1. **Core principles of responsible AI:**\n",
    "   The guide outlines core principles of responsible AI, which include fairness and inclusion, robustness and safety, privacy and security, and transparency and control. Additionally, it emphasizes the importance of governance and accountability mechanisms to ensure these principles are upheld throughout the development and deployment of AI systems.\n",
    "\n",
    "2. **Meta's open approach and AI innovation:**\n",
    "   Meta's open approach to AI innovation involves open-sourcing code and datasets, contributing to the AI community's infrastructure, and making large language models available for research. This approach fosters a vibrant AI-innovation ecosystem, driving breakthroughs in various sectors and enabling exploratory research and large-scale production deployment. It also draws upon the collective wisdom and diversity of the AI community to improve and democratize AI technology.\n",
    "\n",
    "3. **Stages of responsible LLM product development:**\n",
    "   The guide identifies four stages of responsible LLM product development: determining the use case, fine-tuning for the product, addressing input- and output-level risks, and building transparency and reporting mechanisms in user interactions. Each stage involves specific considerations and mitigation strategies to ensure the safe and effective deployment of LLM-powered products.\n",
    "\n",
    "4. **Examples of product-specific fine-tuning:**\n",
    "   Product-specific fine-tuning examples provided in the guide include text summarization, question answering, and sentiment analysis. For instance, a pretrained language model can be fine-tuned on a dataset of long-form documents and summaries for text summarization, on a Q&A dataset for answering questions, and on labeled text reviews for sentiment analysis. These examples demonstrate how fine-tuning can tailor a model's capabilities to specific use cases, enhancing performance and applicability.\n",
    "\n",
    "5. **Considerations for defining content policies:**\n",
    "   When defining content policies for LLMs, developers should consider the intended use and audience of their product, legal and safety limitations, and the needs of specific user communities. Content policies should outline allowable content and safety limitations, which will guide data annotation and safety fine-tuning. It is also important to address potential biases in human feedback and data annotation processes to ensure fairness and objectivity.\n",
    "\n",
    "6. **Benefits of democratizing access to large language models:**\n",
    "   Democratizing access to large language models, as discussed in the guide, reduces barriers to entry for small businesses and fosters innovation across various sectors. By making these models widely available, small organizations can leverage advanced AI technology without incurring prohibitive costs, leading to economic growth and a more level playing field. This approach also promotes collaboration and collective improvement of AI models, ensuring that advancements benefit a broader range of users and applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fb2448a-c874-42bb-824a-48eb32fa287f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nn_rag.components.retrieval.Retrieval at 0x7ff033d70b50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag = Retrieval.from_memory()\n",
    "rag.set_source_uri('chroma:///')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d1aaaab-ab57-47a2-884a-b382347bb41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 4. What are some examples of product-specific fine-tuning for LLMs?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e06f1 th {\n",
       "  font-size: 120%;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_e06f1 .row_heading {\n",
       "  display: none;;\n",
       "}\n",
       "#T_e06f1  .blank {\n",
       "  display: none;;\n",
       "}\n",
       "#T_e06f1_row0_col0, #T_e06f1_row0_col1, #T_e06f1_row0_col2, #T_e06f1_row1_col0, #T_e06f1_row1_col1, #T_e06f1_row1_col2, #T_e06f1_row2_col0, #T_e06f1_row2_col1, #T_e06f1_row2_col2, #T_e06f1_row3_col0, #T_e06f1_row3_col1, #T_e06f1_row3_col2, #T_e06f1_row4_col0, #T_e06f1_row4_col1, #T_e06f1_row4_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e06f1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e06f1_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
       "      <th id=\"T_e06f1_level0_col1\" class=\"col_heading level0 col1\" >distance</th>\n",
       "      <th id=\"T_e06f1_level0_col2\" class=\"col_heading level0 col2\" >source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e06f1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e06f1_row0_col0\" class=\"data row0 col0\" >general_104</td>\n",
       "      <td id=\"T_e06f1_row0_col1\" class=\"data row0 col1\" >1.3518</td>\n",
       "      <td id=\"T_e06f1_row0_col2\" class=\"data row0 col2\" >nd control to users, which can lead to  greater satisfaction and trust in the feature.  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e06f1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e06f1_row1_col0\" class=\"data row1 col0\" >general_41</td>\n",
       "      <td id=\"T_e06f1_row1_col1\" class=\"data row1 col1\" >1.3536</td>\n",
       "      <td id=\"T_e06f1_row1_col2\" class=\"data row1 col2\" >This section  outlines the considerations and mitigation strategies  available at each stage of product development   and deployment.   At a high level these stages include:   1.\t Determine use case 2.\t  Fine-tune for product 3.\t Address input- and   output-level risks 4.\t Build transparency and  reporting mechanisms in   user interactions Responsible LLM product  development stages 1 Determine use case An important decision in the development process  is which use case(s) to focus on.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e06f1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e06f1_row2_col0\" class=\"data row2 col0\" >general_30</td>\n",
       "      <td id=\"T_e06f1_row2_col1\" class=\"data row2 col1\" >1.3700</td>\n",
       "      <td id=\"T_e06f1_row2_col2\" class=\"data row2 col2\" >At various points in the product development  lifecycle, developers make decisions that shape the  objectives and functionality of the feature, which can  introduce potential risks. These decision points also  provide opportunities to mitigate potential risks.    It is critical that developers examine each layer of the  product to determine which potential risks may arise  based on the product objectives and design,   and implement mitigation strategies accordingly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e06f1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e06f1_row3_col0\" class=\"data row3 col0\" >general_113</td>\n",
       "      <td id=\"T_e06f1_row3_col1\" class=\"data row3 col1\" >1.3724</td>\n",
       "      <td id=\"T_e06f1_row3_col2\" class=\"data row3 col2\" >For example, a  user could select or reject outputs from a list of  multiple options. Offering editing capabilities  can also enhance a user’s sense of agency  over outputs, and developers should consider  education flows that can set a user up for  success, such as offering prompt suggestions or  explanations of how to improve an output.  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e06f1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e06f1_row4_col0\" class=\"data row4 col0\" >general_12</td>\n",
       "      <td id=\"T_e06f1_row4_col1\" class=\"data row4 col1\" >1.3830</td>\n",
       "      <td id=\"T_e06f1_row4_col2\" class=\"data row4 col2\" > community to realize  the benefits of this technology.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff033d70910>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "answer = rag.tools.query_similarity(query, limit=5)\n",
    "rag.table_report(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c279bb8-ca82-4e72-93e4-04903f642a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 4. What are some examples of product-specific fine-tuning for LLMs?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_aa865 th {\n",
       "  font-size: 120%;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_aa865 .row_heading {\n",
       "  display: none;;\n",
       "}\n",
       "#T_aa865  .blank {\n",
       "  display: none;;\n",
       "}\n",
       "#T_aa865_row0_col0, #T_aa865_row0_col1, #T_aa865_row0_col2, #T_aa865_row1_col0, #T_aa865_row1_col1, #T_aa865_row1_col2, #T_aa865_row2_col0, #T_aa865_row2_col1, #T_aa865_row2_col2, #T_aa865_row3_col0, #T_aa865_row3_col1, #T_aa865_row3_col2, #T_aa865_row4_col0, #T_aa865_row4_col1, #T_aa865_row4_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_aa865\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_aa865_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
       "      <th id=\"T_aa865_level0_col1\" class=\"col_heading level0 col1\" >cross-encoder_score</th>\n",
       "      <th id=\"T_aa865_level0_col2\" class=\"col_heading level0 col2\" >source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_aa865_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_aa865_row0_col0\" class=\"data row0 col0\" >general_52</td>\n",
       "      <td id=\"T_aa865_row0_col1\" class=\"data row0 col1\" >0.5478</td>\n",
       "      <td id=\"T_aa865_row0_col2\" class=\"data row0 col2\" >By training the model on this task- specific dataset, it can learn to predict sentiment  in text accurately. These examples showcase how fine-tuning an LLM  can be used to specialize the model’s capabilities for  specific use cases, improving its performance and  making it more suitable for specific applications.    The choice of the foundation model and the task- specific dataset plays a crucial role in achieving the  desired results.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa865_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_aa865_row1_col0\" class=\"data row1 col0\" >general_30</td>\n",
       "      <td id=\"T_aa865_row1_col1\" class=\"data row1 col1\" >0.5128</td>\n",
       "      <td id=\"T_aa865_row1_col2\" class=\"data row1 col2\" >At various points in the product development  lifecycle, developers make decisions that shape the  objectives and functionality of the feature, which can  introduce potential risks. These decision points also  provide opportunities to mitigate potential risks.    It is critical that developers examine each layer of the  product to determine which potential risks may arise  based on the product objectives and design,   and implement mitigation strategies accordingly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa865_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_aa865_row2_col0\" class=\"data row2 col0\" >general_18</td>\n",
       "      <td id=\"T_aa865_row2_col1\" class=\"data row2 col1\" >0.4918</td>\n",
       "      <td id=\"T_aa865_row2_col2\" class=\"data row2 col2\" >Decisions to implement  best practices should be evaluated based on the  jurisdiction where your products will be deployed and  should follow your company’s internal legal and risk  management processes. How to use this guide This guide is a resource for developers that outlines  common approaches to building responsibly at each  level of an LLM-powered product. It covers best  practices and considerations that developers should  evaluate in the context of their specific use case and  market.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa865_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_aa865_row3_col0\" class=\"data row3 col0\" >general_41</td>\n",
       "      <td id=\"T_aa865_row3_col1\" class=\"data row3 col1\" >0.4916</td>\n",
       "      <td id=\"T_aa865_row3_col2\" class=\"data row3 col2\" >This section  outlines the considerations and mitigation strategies  available at each stage of product development   and deployment.   At a high level these stages include:   1.\t Determine use case 2.\t  Fine-tune for product 3.\t Address input- and   output-level risks 4.\t Build transparency and  reporting mechanisms in   user interactions Responsible LLM product  development stages 1 Determine use case An important decision in the development process  is which use case(s) to focus on.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa865_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_aa865_row4_col0\" class=\"data row4 col0\" >general_40</td>\n",
       "      <td id=\"T_aa865_row4_col1\" class=\"data row4 col1\" >0.4908</td>\n",
       "      <td id=\"T_aa865_row4_col2\" class=\"data row4 col2\" >It may also be necessary  to establish new terms of service and policies specific  to LLMs, or notify users about how their data or  feedback provided will be used in fine-tuning. Development of the  foundation model 6 JULY 2023 \f",
       "Developers will identify a specific product use case  for the released model, and are responsible for  assessing risks associated with that use case and  applying best practices to ensure safety.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff02614f130>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "answer = rag.tools.query_reranker(query)\n",
    "rag.table_report(answer, headers='distance', drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07281b73-a527-47f8-947c-f31931ee49ed",
   "metadata": {},
   "source": [
    "### Tidy up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cdc499d-e2c5-4c88-87e6-f6051df849d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag.remove_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d3b9ea-bdff-4988-b814-c4bba7be5f9a",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
