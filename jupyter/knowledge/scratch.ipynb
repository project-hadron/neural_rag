{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d448bfe-19b5-4fdb-86ce-658e94d2049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves you having to use print as all exposed variables are printed in the cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23954339-a56c-4067-9def-550397dbf8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pyarrow as pa\n",
    "import pyarrow.compute as pc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3338b3bc-a199-441c-a6be-b2c5585e6a70",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f489c0b2-8b59-41fc-9017-f5bbaf2df4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_rag import Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b5d30a2-176e-4a69-8c07-d4957763326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance of capability\n",
    "kn = Knowledge.from_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69da3e9d-c48d-4fc9-ab52-39ac982cdf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = kn.set_source_uri('hadron/source/Gen AI Best Practices.pdf').load_source_canonical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "621a8805-bcbb-462d-bad5-5ea9bb749c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = kn.tools.text_to_paragraphs(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fdc22dd-4d0a-4952-8f62-bb2a8d13ed2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paragraph: Best Practices in Generative AI\n",
      "Responsible use and development \n",
      "in the modern workplace\n",
      "© Responsible AI Institute 2024  \n",
      "All Rights Reserved |\n",
      "\n",
      "\n",
      "paragraph: Do Not Use Without Permission\n",
      "\f",
      "Executive Summary\n",
      "Generative AI, a technology capable of producing realistic content in the form of text, images,\n",
      "sound, and more, presents signiﬁcant opportunities and challenges for businesses today.\n",
      "With generative AI (GenAI) applications ranging from customer service automation to content\n",
      "creation, the recent explosive adoption of LLM technologies like ChatGPT underscores the\n",
      "potential transformative scale of AI impact, both positive and negative. Potential risks and\n",
      "harms from generative AI impact human rights, privacy, security, labor, fairness, sustainability,\n",
      "and more. Without investing effort to comprehensively address these issues across the\n",
      "enterprise, businesses are exposed to the risks of compliance penalties, consumer harm, loss of\n",
      "trust, damages, and more.\n",
      "To position themselves to responsibly capitalize on this potential, organizations must\n",
      "implement governance to pave the way for trustworthy AI deployment, procurement, sale, and\n",
      "use, as applicable. Applying Responsible AI (RAI) frameworks to generative and other forms of\n",
      "AI across the organization can mitigate pressing risks and threats, allowing the technology’s\n",
      "potential to be maximized.\n",
      "The RAI Institute offers the following set of best practices for responsible generative AI use to\n",
      "guide AI practitioners, executive, and other professionals. These guidelines include\n",
      "recommendations related to gathering the right teams and tools, tracking legal requirements,\n",
      "evolving the workforce, and implementing clear objectives and requirements for generative AI.\n",
      "These best practices are grouped into ﬁve categories of Responsible Generative AI:\n",
      "1.\n",
      "Strategy: Planning, Policies, and Governance\n",
      "2.\n",
      "Workforce: Training, Education, and Upskilling\n",
      "3.\n",
      "Capacity: Resourcing and Tools\n",
      "4.\n",
      "Practice: Development, Procurement, and Use\n",
      "5.\n",
      "Proactivity: Ongoing Enhancement and Monitoring\n",
      "© Responsible AI Institute 2024 |\n",
      "\n",
      "\n",
      "paragraph: All Rights Reserved |\n",
      "\n",
      "\n",
      "paragraph: Do Not Use Without Permission\n",
      "2\n",
      "\f",
      "Background\n",
      "Generative AI is a type of artiﬁcial intelligence (AI) that creates realistic content like images, text, \n",
      "and videos. It works by using a neural network to learn from a dataset and then generate new \n",
      "content based on what it “learned.” However, generative AI can cause serious harm if not used \n",
      "responsibly, such as privacy risks, bias, security threats, lack of transparency, environmental \n",
      "costs, and more. To optimize returns while mitigating risks, businesses must implement \n",
      "Responsible AI frameworks grounded in leading standards and best practices.\n",
      "Generative AI Today\n",
      "The launch of ChatGPT in late 2022 precipitated widespread interest in harnessing the \n",
      "capabilities of generative AI, especially of large language models (LLMs). The use of GenAI to \n",
      "enable better customer service will be widespread–according to Salesforce’s new generative AI \n",
      "in IT Survey, 77% of senior IT leaders believe that generative AI will help their organization serve \n",
      "their customers faster. For example, generative AI can transform customer service by \n",
      "automating responses to inquiries and providing personalized support, signiﬁcantly reducing \n",
      "wait times and improving customer satisfaction. It also helps analyze customer feedback in \n",
      "real-time, enabling businesses to swiftly address concerns and tailor services to meet evolving \n",
      "needs.\n",
      "Beyond customer service, common uses of GenAI include content creation, where it generates \n",
      "articles, reports, and creative writing, enhancing productivity across various sectors. In design \n",
      "and development, GenAI assists in creating software code, architectural plans, and new product \n",
      "concepts. It also plays a crucial role in data analysis, automating the extraction of insights from \n",
      "large data sets. Moreover, personalized education and training solutions beneﬁt from GenAI's \n",
      "ability to adapt learning materials to the user's needs.\n",
      "As organizations adopt GenAI today, considerations and guidelines for responsible use become \n",
      "increasingly important to address potential biases and ensure privacy and security.\n",
      "© Responsible AI Institute 2024 |\n",
      "\n",
      "\n",
      "paragraph: All Rights Reserved |\n",
      "\n",
      "\n",
      "paragraph: Do Not Use Without Permission\n",
      "© Responsible AI Institute 2024 |\n",
      "\n",
      "\n",
      "paragraph: All Rights Reserved |\n",
      "\n",
      "\n",
      "paragraph: Do Not Use Without Permission\n",
      "3\n",
      "\f",
      "Risks of Generative AI\n",
      "Generative AI technology can cause harm if not used responsibly. One risk is that it can be used\n",
      "to mislead people with fake videos and images, such as deepfakes used to scam or\n",
      "misrepresent individuals. Generative AI can also cause harm with biased outputs if it's only\n",
      "trained on information from certain groups, which can lead to unfair and unrepresentative\n",
      "outcomes. For example, when prompted to describe or depict a “professional person in the\n",
      "workplace,” an AI system that was trained on biased data might omit photos of women,\n",
      "particularly women of color.\n",
      "Furthermore, AI systems can generate factually inaccurate outputs, even making up or\n",
      "“hallucinating” research reports, laws, or historical events in their outputs. This hallucination\n",
      "occurs when an AI system learns from data and produces its own new, plausible-seeming but\n",
      "fabricated information. This can occur due to data quality and mitigation issues such as biased\n",
      "or limited training data and model overﬁtting in response to the data.\n",
      "There are also other risks associated with generative AI, such as security problems. For\n",
      "example, generative AI can rely on large-scale datasets that hold private information about\n",
      "individuals that can be elicited through prompts. This also poses intellectual property concerns\n",
      "in terms of both the inputs and outputs to the AI. For example, a recent study of over 10,000\n",
      "employees found that 15 percent of employees input company data into ChatGPT, putting their\n",
      "company at risk of a security breach. Security breaches can happen due to a generative AI\n",
      "system’s vulnerability to threats such as model theft, data poisoning, and adversarial attacks.\n",
      "Another risk is a lack of transparency in the AI’s decision-making processes, which can confuse\n",
      "both users and developers on a system’s outputs and blur the lines of legal liability.\n",
      "According to a Salesforce survey, many IT leaders share a variety of concerns related to\n",
      "implementing GenAI in their organizations. 79% of leaders were concerned about potential\n",
      "security risks, 59% believed generative AI outputs are inaccurate, and 63% believed that there is\n",
      "bias in generative AI outputs, including misinformation and hate speech. 71% of leaders also\n",
      "believed that generative AI would increase their carbon footprint through increased IT energy\n",
      "use.\n",
      "LLMs also pose new risks due to their training style and propensity to be procured for third-party\n",
      "use and or integrated into downstream applications. LLMs are notoriously obscure across\n",
      "explainability and interpretability dimensions, leading to unpredictable behaviors and\n",
      "vulnerabilities. There are also privacy and copyright concerns related to the use of users’ and\n",
      "data subjects’ data for training, which may lead to legal challenges and penalties in near future.\n",
      "© Responsible AI Institute 2024 |\n",
      "\n",
      "\n",
      "paragraph: All Rights Reserved |\n",
      "\n",
      "\n",
      "paragraph: Do Not Use Without Permission\n",
      "4\n",
      "\f",
      "Why a Responsible Approach Generative AI\n",
      "In response to the myriad risks that generative AI poses to both the ﬁnancial and reputational \n",
      "standing of organizations, as well as to the safety and rights of the public, organizations are \n",
      "urged to incorporate Responsible AI principles into their operations and product development. \n",
      "Responsible AI represents a comprehensive, stakeholder-driven methodology for the design, \n",
      "deployment, and implementation of technology. It emphasizes adherence to regulations, laws, \n",
      "and organizational values as central to AI creation and decision-making processes, applicable at \n",
      "both organizational and product levels.\n",
      "AI technologies, by their nature, carry inherent risks. The decisions shaping the design, \n",
      "development, deployment, evaluation, and utilization of AI systems often reﬂect systemic biases \n",
      "and human cognitive limitations. These risks extend beyond individual developers, affecting \n",
      "entire organizations and potentially leading to widespread societal impacts. Traditional \n",
      "corporate governance structures are ill-equipped to keep pace with AI's rapid development, and \n",
      "existing risk management frameworks fail to address the unique challenges AI systems \n",
      "introduce.\n",
      "AI technologies present both new and ampliﬁed risks compared to traditional software. For \n",
      "instance, the data fueling AI systems might not accurately reﬂect the intended context or use, \n",
      "potentially lacking a reliable ground truth and introducing harmful biases. The reliance on \n",
      "extensive, complex data for training, alongside the potential for signiﬁcant changes during this \n",
      "process, underscores the uniqueness of AI-speciﬁc risks. These include the detachment of \n",
      "training datasets from their intended context, the enormous scale and complexity of AI systems, \n",
      "and the challenges associated with managing pre-trained models.\n",
      "Furthermore, AI systems face unique challenges such as increased statistical uncertainty, bias \n",
      "management issues, privacy risks due to enhanced data aggregation capabilities, and the \n",
      "necessity for more frequent maintenance. The opacity of AI systems and concerns over \n",
      "reproducibility, coupled with underdeveloped standards for software testing and documentation, \n",
      "highlight the need for AI-speciﬁc risk management and strategic planning. These strategies \n",
      "must clearly articulate objectives and delineate human roles and responsibilities in overseeing \n",
      "AI systems, ensuring that organizations can navigate the complexities of generative AI \n",
      "responsibly and effectively.\n",
      "Furthermore, demand for responsible trustworthy AI is only growing. A study by Edelman \n",
      "showed that 81% of consumers prefer purchasing from companies that prioritize data privacy \n",
      "and security. Furthermore, research by PwC found that 60% of consumers are more likely to \n",
      "trust companies that are transparent about their AI use. According to a report by the Deloitte AI \n",
      "Institute and US Chamber of Commerce, a trustworthy AI approach “can mitigate risks that\n",
      "© Responsible AI Institute 2024 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in p['paragraph'][:10]:\n",
    "    print(f'paragraph: {item}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a1995a3-3056-475f-87ae-1ff6fdde0fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nouns - [('use', 1), ('development', 1), ('workplace', 1), ('|', 1)]\n",
      "nouns - [('risks', 3), ('technology', 2), ('content', 2), ('businesses', 2), ('impact', 2)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('customer', 5), ('content', 3), ('service', 3), ('privacy', 2), ('risks', 2)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('Permission', 1), ('©', 1), ('|', 1)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('data', 9), ('outputs', 7), ('system', 4), ('risk', 3), ('information', 3)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('risks', 7), ('systems', 7), ('organizations', 4), ('data', 4), ('development', 3)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('Permission', 1), ('©', 1), ('|', 1)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('systems', 3), ('applications', 2), ('organizations', 2), ('strategies', 2), ('use', 2)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('practices', 6), ('organizations', 3), ('development', 3), ('use', 2), ('Practices', 1)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('team', 7), ('requirements', 4), ('deployment', 3), ('standardization', 3), ('development', 3)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('model', 5), ('organization', 4), ('models', 4), ('●', 3), ('resources', 3)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('data', 16), ('model', 8), ('quality', 5), ('considerations', 4), ('training', 4)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('governance', 6), ('development', 6), ('policies', 5), ('deployment', 4), ('policy', 4)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('risk', 8), ('management', 5), ('systems', 4), ('risks', 4), ('approach', 3)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('training', 8), ('roles', 4), ('compliance', 4), ('Training', 3), ('resources', 3)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('model', 6), ('function', 5), ('●', 4), ('training', 3), ('information', 3)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('cybersecurity', 5), ('organization', 4), ('security', 3), ('●', 2), ('models', 2)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('resources', 5), ('tools', 5), ('system', 5), ('management', 4), ('processes', 4)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('development', 14), ('model', 7), ('system', 5), ('risk', 4), ('data', 4)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('model', 10), ('development', 6), ('models', 5), ('performance', 4), ('●', 3)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('●', 4), ('procurement', 4), ('use', 4), ('model', 3), ('suppliers', 3)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('information', 10), ('employees', 8), ('systems', 5), ('impacts', 2), ('guidance', 2)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('systems', 4), ('monitoring', 3), ('audits', 3), ('risks', 2), ('organization', 2)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('beneﬁts', 3), ('risks', 3), ('business', 3), ('technology', 2), ('privacy', 2)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('technologies', 3), ('content', 3), ('data', 2), ('deﬁnitions', 2), ('ﬁeld', 2)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('bias', 8), ('systems', 7), ('data', 6), ('system', 5), ('management', 4)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('data', 13), ('process', 7), ('system', 5), ('governance', 4), ('management', 3)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('system', 5), ('design', 5), ('risk', 5), ('governance', 4), ('processes', 4)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('characteristics', 7), ('systems', 4), ('system', 4), ('Source', 3), ('accountability', 2)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('system', 6), ('systems', 6), ('conditions', 3), ('use', 3), ('time', 2)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('system', 6), ('biases', 5), ('decision', 4), ('bias', 4), ('systems', 3)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('system', 11), ('concepts', 7), ('product', 6), ('Covers', 5), ('team', 4)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - [('organizations', 2), ('member', 2), ('members', 2), ('journeys', 1), ('support', 1)]\n",
      "nouns - [('|', 1)]\n",
      "nouns - []\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "for text in p['paragraph']:\n",
    "    doc = nlp(text.as_py())\n",
    "    \n",
    "    # all tokens that arent stop words or punctuations\n",
    "    words = [token.text\n",
    "             for token in doc\n",
    "             if not token.is_stop and not token.is_punct]\n",
    "    \n",
    "    # noun tokens that arent stop words or punctuations\n",
    "    nouns = [token.text\n",
    "             for token in doc\n",
    "             if (not token.is_stop and\n",
    "                 not token.is_punct and\n",
    "                 token.pos_ == \"NOUN\")]\n",
    "    \n",
    "    # five most common tokens\n",
    "    word_freq = Counter(words)\n",
    "    common_words = word_freq.most_common(5)\n",
    "    \n",
    "    # five most common noun tokens\n",
    "    noun_freq = Counter(nouns)\n",
    "    common_nouns = noun_freq.most_common(5)\n",
    "    print(f\"nouns - {common_nouns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aac0434-a9ca-4875-8ef6-cc1d525a5ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
