{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "962e2eab-fef2-4393-8e03-836e7921a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves you having to use print as all exposed variables are printed in the cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68bdaf3a-78fb-438b-9590-d4feb46ad151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.compute as pc\n",
    "from nn_rag import Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709d851e-70d0-4767-819f-e5571262c431",
   "metadata": {},
   "source": [
    "### Instantiate capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b85ae8c1-598a-4764-97b0-7b882e3fadc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn = Knowledge.from_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "361cb284-9dbd-461b-9fbe-6abf87fed6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = kn.set_source_uri(\"source/Gen AI Best Practices.pdf\").load_source_canonical()\n",
    "kn.set_persist_uri('./hadron/data/gen_ai_best_practice.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b990c759-1ea5-467c-9f33-b9acd6a47ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['text']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Best Practices in Generative AI\\nResponsible use and development \\nin the modern workplace\\n© Responsible AI Institute 2024  \\nAll Rights Reserved | Do Not Use Without Permission\\n\\x0cExecutive Summary\\nGenerative AI, a technology capable of producing realistic content in the form of text, images,\\nsound, and'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl.shape\n",
    "tbl.column_names\n",
    "tbl.column('text').to_pylist()[0][:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fe3fce-bcba-4c3c-a422-09595a350230",
   "metadata": {},
   "source": [
    "### Tidy the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29e41f1b-9f7d-4679-866b-345d7ea9fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = kn.tools.pattern_replace(tbl, 'text', '\\n', ' ')\n",
    "tbl = kn.tools.pattern_replace(tbl, 'text', '  ', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26fef06-d700-4ec1-944e-cdf80ce03df0",
   "metadata": {},
   "source": [
    "### Profling\n",
    "#### discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b103bdd8-3502-4028-89d7-81b247024742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_307a1 th {\n",
       "  font-size: 120%;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_307a1 .row_heading {\n",
       "  display: none;;\n",
       "}\n",
       "#T_307a1  .blank {\n",
       "  display: none;;\n",
       "}\n",
       "#T_307a1_row0_col0, #T_307a1_row0_col1, #T_307a1_row0_col2, #T_307a1_row0_col3, #T_307a1_row0_col4, #T_307a1_row1_col0, #T_307a1_row1_col1, #T_307a1_row1_col2, #T_307a1_row1_col3, #T_307a1_row1_col4, #T_307a1_row2_col0, #T_307a1_row2_col1, #T_307a1_row2_col2, #T_307a1_row2_col3, #T_307a1_row2_col4, #T_307a1_row3_col0, #T_307a1_row3_col1, #T_307a1_row3_col2, #T_307a1_row3_col3, #T_307a1_row3_col4 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_307a1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_307a1_level0_col0\" class=\"col_heading level0 col0\" >sentence</th>\n",
       "      <th id=\"T_307a1_level0_col1\" class=\"col_heading level0 col1\" >sentence_num</th>\n",
       "      <th id=\"T_307a1_level0_col2\" class=\"col_heading level0 col2\" >char_count</th>\n",
       "      <th id=\"T_307a1_level0_col3\" class=\"col_heading level0 col3\" >word_count</th>\n",
       "      <th id=\"T_307a1_level0_col4\" class=\"col_heading level0 col4\" >token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_307a1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_307a1_row0_col0\" class=\"data row0 col0\" >Best Practices in Generative AI Responsible use and development in the modern workplace © Responsible AI Institute 2024  All Rights Reserved | Do Not Use Without Permission \f",
       "Executive Summary Generative AI, a technology capable of producing realistic content in the form of text, images, sound, and more, presents signiﬁcant opportunities and challenges for businesses today.</td>\n",
       "      <td id=\"T_307a1_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_307a1_row0_col2\" class=\"data row0 col2\" >375</td>\n",
       "      <td id=\"T_307a1_row0_col3\" class=\"data row0 col3\" >56</td>\n",
       "      <td id=\"T_307a1_row0_col4\" class=\"data row0 col4\" >94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_307a1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_307a1_row1_col0\" class=\"data row1 col0\" >With generative AI (GenAI) applications ranging from customer service automation to content creation, the recent explosive adoption of LLM technologies like ChatGPT underscores the potential transformative scale of AI impact, both positive and negative.</td>\n",
       "      <td id=\"T_307a1_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "      <td id=\"T_307a1_row1_col2\" class=\"data row1 col2\" >253</td>\n",
       "      <td id=\"T_307a1_row1_col3\" class=\"data row1 col3\" >34</td>\n",
       "      <td id=\"T_307a1_row1_col4\" class=\"data row1 col4\" >63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_307a1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_307a1_row2_col0\" class=\"data row2 col0\" >Potential risks and harms from generative AI impact human rights, privacy, security, labor, fairness, sustainability, and more.</td>\n",
       "      <td id=\"T_307a1_row2_col1\" class=\"data row2 col1\" >2</td>\n",
       "      <td id=\"T_307a1_row2_col2\" class=\"data row2 col2\" >127</td>\n",
       "      <td id=\"T_307a1_row2_col3\" class=\"data row2 col3\" >17</td>\n",
       "      <td id=\"T_307a1_row2_col4\" class=\"data row2 col4\" >32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_307a1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_307a1_row3_col0\" class=\"data row3 col0\" >Without investing effort to comprehensively address these issues across the enterprise, businesses are exposed to the risks of compliance penalties, consumer harm, loss of trust, damages, and more.</td>\n",
       "      <td id=\"T_307a1_row3_col1\" class=\"data row3 col1\" >3</td>\n",
       "      <td id=\"T_307a1_row3_col2\" class=\"data row3 col2\" >197</td>\n",
       "      <td id=\"T_307a1_row3_col3\" class=\"data row3 col3\" >28</td>\n",
       "      <td id=\"T_307a1_row3_col4\" class=\"data row3 col4\" >49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb6102e7e50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = kn.tools.text_profiler(tbl)\n",
    "sentences.shape\n",
    "kn.table_report(sentences, head=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac1b8436-846a-4824-95ad-4779be9f640f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min word count 1\n",
      "max word count 188\n",
      "mean word count 25\n"
     ]
    }
   ],
   "source": [
    "print(f\"min word count {pc.min(sentences['word_count']).as_py()}\")\n",
    "print(f\"max word count {pc.max(sentences['word_count']).as_py()}\")\n",
    "print(f\"mean word count {round(pc.mean(sentences['word_count']).as_py())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44b751ef-bd2e-44f5-bfad-5622fa36a0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence with 2 or less words 16\n"
     ]
    }
   ],
   "source": [
    "print(f\"sentence with 2 or less words {pc.count(pc.filter(sentences['word_count'], pc.less_equal(sentences['word_count'], 2))).as_py()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda4cf0b-75be-4ce5-ba01-309ea117ab54",
   "metadata": {},
   "source": [
    "#### check small sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e119a43-e053-4f47-92c4-9fd4aa2125e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "short = kn.tools.filter_on_condition(sentences, header='word_count', condition=(2, 'less_equal', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa6db8a6-713e-48c0-8da8-d177a352f2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8acc1 th {\n",
       "  font-size: 120%;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_8acc1 .row_heading {\n",
       "  display: none;;\n",
       "}\n",
       "#T_8acc1  .blank {\n",
       "  display: none;;\n",
       "}\n",
       "#T_8acc1_row0_col0, #T_8acc1_row0_col1, #T_8acc1_row0_col2, #T_8acc1_row0_col3, #T_8acc1_row0_col4, #T_8acc1_row1_col0, #T_8acc1_row1_col1, #T_8acc1_row1_col2, #T_8acc1_row1_col3, #T_8acc1_row1_col4, #T_8acc1_row2_col0, #T_8acc1_row2_col1, #T_8acc1_row2_col2, #T_8acc1_row2_col3, #T_8acc1_row2_col4, #T_8acc1_row3_col0, #T_8acc1_row3_col1, #T_8acc1_row3_col2, #T_8acc1_row3_col3, #T_8acc1_row3_col4, #T_8acc1_row4_col0, #T_8acc1_row4_col1, #T_8acc1_row4_col2, #T_8acc1_row4_col3, #T_8acc1_row4_col4 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8acc1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8acc1_level0_col0\" class=\"col_heading level0 col0\" >sentence</th>\n",
       "      <th id=\"T_8acc1_level0_col1\" class=\"col_heading level0 col1\" >sentence_num</th>\n",
       "      <th id=\"T_8acc1_level0_col2\" class=\"col_heading level0 col2\" >char_count</th>\n",
       "      <th id=\"T_8acc1_level0_col3\" class=\"col_heading level0 col3\" >word_count</th>\n",
       "      <th id=\"T_8acc1_level0_col4\" class=\"col_heading level0 col4\" >token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8acc1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8acc1_row0_col0\" class=\"data row0 col0\" >2.</td>\n",
       "      <td id=\"T_8acc1_row0_col1\" class=\"data row0 col1\" >78</td>\n",
       "      <td id=\"T_8acc1_row0_col2\" class=\"data row0 col2\" >2</td>\n",
       "      <td id=\"T_8acc1_row0_col3\" class=\"data row0 col3\" >1</td>\n",
       "      <td id=\"T_8acc1_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8acc1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8acc1_row1_col0\" class=\"data row1 col0\" >3.</td>\n",
       "      <td id=\"T_8acc1_row1_col1\" class=\"data row1 col1\" >80</td>\n",
       "      <td id=\"T_8acc1_row1_col2\" class=\"data row1 col2\" >2</td>\n",
       "      <td id=\"T_8acc1_row1_col3\" class=\"data row1 col3\" >1</td>\n",
       "      <td id=\"T_8acc1_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8acc1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8acc1_row2_col0\" class=\"data row2 col0\" >4.</td>\n",
       "      <td id=\"T_8acc1_row2_col1\" class=\"data row2 col1\" >82</td>\n",
       "      <td id=\"T_8acc1_row2_col2\" class=\"data row2 col2\" >2</td>\n",
       "      <td id=\"T_8acc1_row2_col3\" class=\"data row2 col3\" >1</td>\n",
       "      <td id=\"T_8acc1_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8acc1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_8acc1_row3_col0\" class=\"data row3 col0\" >5.</td>\n",
       "      <td id=\"T_8acc1_row3_col1\" class=\"data row3 col1\" >84</td>\n",
       "      <td id=\"T_8acc1_row3_col2\" class=\"data row3 col2\" >2</td>\n",
       "      <td id=\"T_8acc1_row3_col3\" class=\"data row3 col3\" >1</td>\n",
       "      <td id=\"T_8acc1_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8acc1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_8acc1_row4_col0\" class=\"data row4 col0\" >1.</td>\n",
       "      <td id=\"T_8acc1_row4_col1\" class=\"data row4 col1\" >332</td>\n",
       "      <td id=\"T_8acc1_row4_col2\" class=\"data row4 col2\" >2</td>\n",
       "      <td id=\"T_8acc1_row4_col3\" class=\"data row4 col3\" >1</td>\n",
       "      <td id=\"T_8acc1_row4_col4\" class=\"data row4 col4\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb60ea79000>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn.table_report(short, head=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd42e6be-f258-4c3f-9be2-df715e94750b",
   "metadata": {},
   "source": [
    "It looks like these are reference numbers that might compromise our paragraph chunks. At this point we could reverse the condition and remove the reference numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48e2b855-49ec-4881-9755-801c12c8a10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = kn.tools.filter_on_condition(sentences, header='word_count', condition=(1, 'greater', None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f247cba5-8667-4531-97c7-c3b7a1f318ad",
   "metadata": {},
   "source": [
    "Alternatively we could look at removing specific sentences or groups of sentences that are not relevant to all text.\n",
    "An example of this might be a PDF with an introductory pre-face and indexing where the first 40 pages should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0b85c8-6859-4fb6-8374-582add89ca3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d00b208-3e72-435c-bdf1-deaa89c8de35",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be78fdc2-df14-4fad-bcf2-60490b6e9629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_22746 th {\n",
       "  font-size: 120%;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_22746 .row_heading {\n",
       "  display: none;;\n",
       "}\n",
       "#T_22746  .blank {\n",
       "  display: none;;\n",
       "}\n",
       "#T_22746_row0_col0, #T_22746_row0_col1, #T_22746_row0_col2, #T_22746_row0_col3, #T_22746_row0_col4, #T_22746_row1_col0, #T_22746_row1_col1, #T_22746_row1_col2, #T_22746_row1_col3, #T_22746_row1_col4, #T_22746_row2_col0, #T_22746_row2_col1, #T_22746_row2_col2, #T_22746_row2_col3, #T_22746_row2_col4, #T_22746_row3_col0, #T_22746_row3_col1, #T_22746_row3_col2, #T_22746_row3_col3, #T_22746_row3_col4 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_22746\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_22746_level0_col0\" class=\"col_heading level0 col0\" >chunk_number</th>\n",
       "      <th id=\"T_22746_level0_col1\" class=\"col_heading level0 col1\" >chunk_sentence_count</th>\n",
       "      <th id=\"T_22746_level0_col2\" class=\"col_heading level0 col2\" >chunk_char_count</th>\n",
       "      <th id=\"T_22746_level0_col3\" class=\"col_heading level0 col3\" >chunk_word_count</th>\n",
       "      <th id=\"T_22746_level0_col4\" class=\"col_heading level0 col4\" >chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_22746_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_22746_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_22746_row0_col1\" class=\"data row0 col1\" >5</td>\n",
       "      <td id=\"T_22746_row0_col2\" class=\"data row0 col2\" >1153</td>\n",
       "      <td id=\"T_22746_row0_col3\" class=\"data row0 col3\" >162</td>\n",
       "      <td id=\"T_22746_row0_col4\" class=\"data row0 col4\" >288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22746_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_22746_row1_col0\" class=\"data row1 col0\" >1</td>\n",
       "      <td id=\"T_22746_row1_col1\" class=\"data row1 col1\" >5</td>\n",
       "      <td id=\"T_22746_row1_col2\" class=\"data row1 col2\" >698</td>\n",
       "      <td id=\"T_22746_row1_col3\" class=\"data row1 col3\" >97</td>\n",
       "      <td id=\"T_22746_row1_col4\" class=\"data row1 col4\" >174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22746_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_22746_row2_col0\" class=\"data row2 col0\" >2</td>\n",
       "      <td id=\"T_22746_row2_col1\" class=\"data row2 col1\" >5</td>\n",
       "      <td id=\"T_22746_row2_col2\" class=\"data row2 col2\" >512</td>\n",
       "      <td id=\"T_22746_row2_col3\" class=\"data row2 col3\" >79</td>\n",
       "      <td id=\"T_22746_row2_col4\" class=\"data row2 col4\" >128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22746_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_22746_row3_col0\" class=\"data row3 col0\" >3</td>\n",
       "      <td id=\"T_22746_row3_col1\" class=\"data row3 col1\" >5</td>\n",
       "      <td id=\"T_22746_row3_col2\" class=\"data row3 col2\" >937</td>\n",
       "      <td id=\"T_22746_row3_col3\" class=\"data row3 col3\" >132</td>\n",
       "      <td id=\"T_22746_row3_col4\" class=\"data row3 col4\" >234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb624aaacb0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = kn.tools.sentence_chunks(sentences, num_sentence_chunk_size=5)\n",
    "chunks.shape\n",
    "kn.table_report(chunks.drop_columns('chunk_text'), head=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "580e9c4e-1cb8-4227-99f0-4f0494ae05c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min chunk token count 28\n",
      "max chunk token count 486\n",
      "mean chunk token count 228\n",
      "total tokens 17345\n"
     ]
    }
   ],
   "source": [
    "print(f\"min chunk token count {pc.min(chunks['chunk_token_count']).as_py()}\")\n",
    "print(f\"max chunk token count {pc.max(chunks['chunk_token_count']).as_py()}\")\n",
    "print(f\"mean chunk token count {round(pc.mean(chunks['chunk_token_count']).as_py())}\")\n",
    "print(f\"total tokens {pc.sum(chunks['chunk_token_count']).as_py()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f83b8-cac6-4ae4-9b7d-05f9c1ee3b95",
   "metadata": {},
   "source": [
    "#### ensure paragraphs are properly formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54e27cdb-4de2-42ab-a46c-823ee731d192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = kn.tools.pattern_replace(chunks, 'chunk_text', r'\\.([A-Z])', r'. \\1', is_regex=True)\n",
    "chunks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caee61a-6506-4025-99d5-d2969a320a10",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1caf4977-4398-45f5-9a48-af84a21cf7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = kn.tools.chunk_embedding(chunks, batch_size=32, embedding_name='all-mpnet-base-v2', device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69f9ab6c-d6df-44a1-b420-1b6172d6726f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.lib.Tensor"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(76, 768)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embedding)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9486bae-6b26-46cf-8acc-c2b20caea0b7",
   "metadata": {},
   "source": [
    "--------------------\n",
    "\n",
    "### Save Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c49f10e7-6e41-4043-a65c-b4425de78934",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn.save_persist_canonical(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55172e89-eff8-4a58-8729-1330f0cbd402",
   "metadata": {},
   "source": [
    "### Query Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "692c3a50-328c-4643-bfdb-2081af0c0036",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'what are the key best practices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "872aff6f-4787-4617-8ade-d46703b0e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = kn.load_persist_canonical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cca8789c-8c60-4c4c-a269-3f599205e53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, indices = kn.tools.score_embedding(tensor, query=query, topk=5,\n",
    "                                          embedding_name='all-mpnet-base-v2', device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca18e56c-de8a-4ce3-a55b-b14af90a5b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import pyarrow as pa\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    print(wrapped_text)\n",
    "    \n",
    "def print_top_results_and_scores(query: str, chunks: pa.Table):\n",
    "    chunk_dict = chunks.to_pylist()\n",
    "    \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    print(\"Results:\")\n",
    "    # Loop through zipped together scores and indicies\n",
    "    for score, index in zip(scores, indices):\n",
    "        print(f\"Score: {score:.4f}\")\n",
    "        print_wrapped(chunk_dict[index][\"chunk_text\"])\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a6a98ba-2da0-4191-8db3-a3ce327e8bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: what are the key best practices\n",
      "\n",
      "Results:\n",
      "Score: 0.4253\n",
      "Index: 15\n",
      "These best practices should be implemented in parallel where appropriate by\n",
      "diverse, inclusive, and cross-functional teams. These best practices are grouped\n",
      "into ﬁve categories of Responsible Generative AI: 1. Strategy: This encompasses\n",
      "Planning, Policies, and Governance, ensuring that the organization's GenAI\n",
      "initiatives are well-aligned with its overall goals and compliant with relevant\n",
      "regulations. Workforce: Focuses on Training, Education, and Upskilling,\n",
      "equipping employees with the necessary knowledge and skills to effectively\n",
      "engage with GenAI technologies. Capacity: Relates to Resourcing and Tools,\n",
      "addressing the need for adequate resources and tools to support GenAI\n",
      "development and deployment.\n",
      "\n",
      "\n",
      "Score: 0.3860\n",
      "Index: 40\n",
      "● Performance metrics: Deﬁne and track relevant performance metrics to\n",
      "quantitatively assess the model's progress and compare different iterations. ●\n",
      "Documentation: Thoroughly document the model development process, including\n",
      "design decisions, parameter choices, and issues encountered, for future\n",
      "reference and knowledge sharing. ● Version Control: Use version control systems\n",
      "to manage model code, data, and conﬁgurations, to facilitate collaboration and\n",
      "reproducibility. Data versioning is also important to consider when thinking\n",
      "about reproducibility ● Continuous monitoring: Set up continuous monitoring of\n",
      "the model's performance in real-world scenarios, to identify potential issues\n",
      "and adapt to changing conditions. ○ AI model performance changes with updates\n",
      "from the model developer team.\n",
      "\n",
      "\n",
      "Score: 0.3636\n",
      "Index: 22\n",
      "● Quality: Strong data quality aligns data used for the development and\n",
      "enhancement of AI system with objectives and RAI best practices. Consider\n",
      "articulating and documenting requirements for acquiring, selecting, using, and\n",
      "providing data. Encourage organization-wide data provenance by standardizing\n",
      "processes for verifying and recording the provenance of data used in AI systems\n",
      "over the AI and data lifecycles. Guarantee that GenAI training data is of high\n",
      "quality and directly relevant to the initially deﬁned use cases. ● Diversity and\n",
      "Representativeness: Ensure the training dataset is diverse and representative of\n",
      "various real-world scenarios to minimize bias and enhance the model's\n",
      "generalizability.\n",
      "\n",
      "\n",
      "Score: 0.3527\n",
      "Index: 29\n",
      "Bolster role-relevant and application-specific training Organization should\n",
      "develop or procure responsible AI training resources for speciﬁc roles and\n",
      "determine what kinds of training should be mandatory or encouraged. ● Training\n",
      "programs should include risk, compliance, and RAI training across various\n",
      "functions. Training materials should include case studies and should be\n",
      "engaging, accessible, and effective. ● For example, HR training should cover\n",
      "appropriate uses, risks, and requirements speciﬁc to relevant use cases.\n",
      "Technical users should be trained in model assessment frameworks, research\n",
      "reviews, and analytical techniques on a mandatory basis.\n",
      "\n",
      "\n",
      "Score: 0.3483\n",
      "Index: 25\n",
      "Establish organization-wide GenAI policies and guidelines to set clear\n",
      "expectations and foster collaboration. This can be done in parallel based on\n",
      "context and risk priorities. ● Deﬁne terms and objectives within the GenAI\n",
      "policy and management plan to ensure AI use is valid, reliable, safe, secure,\n",
      "resilient, accountable, transparent, explainable, interpretable, privacy-\n",
      "enhanced, and fair. Incorporate mandatory governance gates for AI system\n",
      "implementation to maintain their suitability, adequacy, effectiveness, and\n",
      "responsibility throughout all lifecycle stages. ● Align GenAI policy with\n",
      "existing organizational RAI, AI, and non-AI policies for coherence and\n",
      "comprehensive governance.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_results_and_scores(query=query, chunks=chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393745fc-ae3f-4e8a-a81b-00bd254b0f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
