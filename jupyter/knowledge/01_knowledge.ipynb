{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962e2eab-fef2-4393-8e03-836e7921a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves you having to use print as all exposed variables are printed in the cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bdaf3a-78fb-438b-9590-d4feb46ad151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.compute as pc\n",
    "from nn_rag import Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709d851e-70d0-4767-819f-e5571262c431",
   "metadata": {},
   "source": [
    "### Instantiate capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85ae8c1-598a-4764-97b0-7b882e3fadc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn = Knowledge.from_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361cb284-9dbd-461b-9fbe-6abf87fed6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"source/Gen AI Best Practices.pdf\"\n",
    "tbl = kn.set_source_uri(uri).load_source_canonical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b990c759-1ea5-467c-9f33-b9acd6a47ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.shape\n",
    "tbl.column_names\n",
    "tbl.column('text').to_pylist()[0][:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fe3fce-bcba-4c3c-a422-09595a350230",
   "metadata": {},
   "source": [
    "### Tidy the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e41f1b-9f7d-4679-866b-345d7ea9fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = kn.tools.correlate_replace(tbl, 'text', '\\n', ' ', intent_order=-1)\n",
    "tbl = kn.tools.correlate_replace(tbl, 'text', '  ', ' ', intent_order=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26fef06-d700-4ec1-944e-cdf80ce03df0",
   "metadata": {},
   "source": [
    "### Profling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103bdd8-3502-4028-89d7-81b247024742",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = kn.tools.text_profiler(tbl)\n",
    "profile.shape\n",
    "kn.table_report(profile, head=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a10b987-08f7-4260-95da-5d8aea544264",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = kn.tools.text_profiler(tbl, to_drop=[0, (2,5)])\n",
    "profile.shape\n",
    "kn.table_report(profile, head=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe64dac8-6e3b-4062-9a9a-a7196af98a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'With generative AI (GenAI) applications ranging from customer service automation to content creation, the recent explosive adoption of LLM technologies like ChatGPT underscores the potential transformative scale of AI impact, both positive and negative. Applying Responsible AI (RAI) frameworks to generative and other forms of AI across the organization can mitigate pressing risks and threats, allowing the technologyâ€™s potential to be maximized. The RAI Institute offers the following set of best practices for responsible generative AI use to guide AI practitioners, executive, and other professionals. These guidelines include recommendations related to gathering the right teams and tools, trac'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = kn.tools.text_profiler(tbl, to_drop=[0, (2,5)], as_text=True)\n",
    "clean_text.shape\n",
    "clean_text.column('text').to_pylist()[0][:700]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d00b208-3e72-435c-bdf1-deaa89c8de35",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be78fdc2-df14-4fad-bcf2-60490b6e9629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['text_name',\n",
       " 'chunk_number',\n",
       " 'sentence_chunks',\n",
       " 'chunk_sentence_count',\n",
       " 'chunk_char_count',\n",
       " 'chunk_word_count',\n",
       " 'chunk_token_count']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = kn.tools.text_chunk(clean_text, text_name='GenAIBestPractice', num_sentence_chunk_size=10)\n",
    "chunks.shape\n",
    "chunks.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caee61a-6506-4025-99d5-d2969a320a10",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1caf4977-4398-45f5-9a48-af84a21cf7a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sentence_chunk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[43mkn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall-mpnet-base-v2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neural/lib/python3.10/site-packages/nn_rag/intent/knowledge_intent.py:294\u001b[0m, in \u001b[0;36mKnowledgeIntent.chunk_embedding\u001b[0;34m(self, canonical, batch_size, embedding_name, device, seed, save_intent, intent_level, intent_order, replace_intent, remove_duplicates)\u001b[0m\n\u001b[1;32m    292\u001b[0m embedding_model \u001b[38;5;241m=\u001b[39m SentenceTransformer(model_name_or_path\u001b[38;5;241m=\u001b[39membedding_name, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# Turn text chunks into a single list\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m text_chunks \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_chunk\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m pages_and_chunks]\n\u001b[1;32m    295\u001b[0m numpy_embedding \u001b[38;5;241m=\u001b[39m embedding_model\u001b[38;5;241m.\u001b[39mencode(text_chunks, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, convert_to_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mTensor\u001b[38;5;241m.\u001b[39mfrom_numpy(numpy_embedding)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neural/lib/python3.10/site-packages/nn_rag/intent/knowledge_intent.py:294\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    292\u001b[0m embedding_model \u001b[38;5;241m=\u001b[39m SentenceTransformer(model_name_or_path\u001b[38;5;241m=\u001b[39membedding_name, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# Turn text chunks into a single list\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m text_chunks \u001b[38;5;241m=\u001b[39m [\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentence_chunk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m pages_and_chunks]\n\u001b[1;32m    295\u001b[0m numpy_embedding \u001b[38;5;241m=\u001b[39m embedding_model\u001b[38;5;241m.\u001b[39mencode(text_chunks, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, convert_to_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mTensor\u001b[38;5;241m.\u001b[39mfrom_numpy(numpy_embedding)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sentence_chunk'"
     ]
    }
   ],
   "source": [
    "embedding = kn.tools.chunk_embedding(chunks, batch_size=32, embedding_name='all-mpnet-base-v2', device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69f9ab6c-d6df-44a1-b420-1b6172d6726f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mtype\u001b[39m(\u001b[43membedding\u001b[49m)\n\u001b[1;32m      2\u001b[0m embedding\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding' is not defined"
     ]
    }
   ],
   "source": [
    "type(embedding)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd0df8-9233-42c6-94ba-3aabe16ea94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn.run_component_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17997d56-64f5-4124-8a3d-0d3cc13c0d6b",
   "metadata": {},
   "source": [
    "### Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff795ff-3a79-4cd4-beb4-55eea3956233",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn.report_intent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e4bd97-7e5f-4dc4-b687-810679fa0c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn.report_connectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a227891-7135-4057-a4ff-fa29ed8c1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn.report_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc796f5-7f22-478a-857d-60f50565b590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
